<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>中文情感词典的构建</title>
    <url>/2019/02/28/2019-02-28-%E4%B8%AD%E6%96%87%E6%83%85%E6%84%9F%E8%AF%8D%E5%85%B8%E7%9A%84%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<p>本文介绍了情感词典的构建方式，文章主要分为：通用情感词典的构建、通用情感词典的扩展、领域情感词典的构建</p>
<span id="more"></span>
<blockquote>
<p>首先，国外英文的情感分析已经取得了很好的效果，得益于英文单词自身分析的便捷性与英文大量的数据集 WordNet。但由于中文的多变性，语义的多重性与数据集的缺乏，使得国内的情感分析暂落后于国外。本文将记录博主在项目中构建情感词典的经验，欢迎大家指正。<br>我们首先将情感词典分为通用情感词典与专用情感词典。</p>
</blockquote>
<h1 id="1-通用情感词典的构建"><a href="#1-通用情感词典的构建" class="headerlink" title="1.通用情感词典的构建"></a>1.通用情感词典的构建</h1><p>   通用情感词典的构建主要是通过将目前开源的情感词典整合起来，筛去重复和无用的单词。<br>   目前网上开源的情感词典包含有：知网（HowNet）情感词典、台湾大学（NTSUSD)简体中文情感极性词典、大连理工大学情感词汇本体。<br>   前两个都可以在网上找到，第三个需要到其学校官网申请，说明完用途即可获得。</p>
<h1 id="2-通用情感词典的扩展"><a href="#2-通用情感词典的扩展" class="headerlink" title="2.通用情感词典的扩展"></a>2.通用情感词典的扩展</h1><p>上述情感词典年代都已经比较久远，所以我们可以采取一定方法对其扩展。这里我们采用的方法是将词典的同义词添加到词典里。<br>我们通过使用哈工大整理的同义词词林来获取词典的同义词，需要一提的是第一版的同义词林年代较为久远，现在也有哈工大整理的同义词林扩展版。<br>使用的链接在这里：<a href="https://blog.csdn.net/sinat_33741547/article/details/80016713">哈工大同义词林扩展版</a><br>使用代码编写时也可以利用Python的Synonyms库来获取同义词。<br>其已经开源，链接为：<a href="https://github.com/huyingxi/Synonyms">synonyms</a><br>如：</p>
<pre><code>import synonyms
print(&quot;人脸: %s&quot; % (synonyms.nearby(&quot;人脸&quot;)))
print(&quot;识别: %s&quot; % (synonyms.nearby(&quot;识别&quot;)))
</code></pre><h1 id="3-领域情感词典的构建"><a href="#3-领域情感词典的构建" class="headerlink" title="3.领域情感词典的构建"></a>3.领域情感词典的构建</h1><p>构建特定领域的情感词典大体有两种方法：基于规则的情感词典构建方法、基于统计的情感词典构建方法。</p>
<p>基于规则的情感词典方法一般是用句型固定、句式不多变的情况。通过对语料进行句法分析，词性标注等操作，得到语料中常用的句型并将其抽象出来，根据抽象出来的句型模板来对新的语料进行模板匹配，以此来选择出新的语料中的情感词，将其加入到对应的情感词典中。</p>
<p>基于统计的情感词典构建方法需要利用PMI互信息计算与左右熵来发现所需要的新词。具体方法我们可以添加情感种子词，来计算分好词的语料中各个词语与情感种子词的互信息度与左右熵，再将互信息度与左右熵结合起来，选择出与情感词关联度最高的TopN个词语，将其添加到对应的情感词典。<br>这里可以参考链接<a href="https://www.jianshu.com/p/e9313fd692ef">link</a></p>
<h3 id="互信息度计算"><a href="#互信息度计算" class="headerlink" title="互信息度计算"></a>互信息度计算</h3><p><img src="https://img-blog.csdnimg.cn/20190228172006936.png" alt="互信息度计算"></p>
<ul>
<li>p(x,y)为两个词一起出现的概率</li>
<li>p(x)为词x出现的概率</li>
<li>p(y)为词y出现的概率</li>
</ul>
<hr>
<p>具体例子：4G， 上网卡，4G上网卡;如果4G的词频是2,上网卡的词频是10,4G上网卡的词频是1，那么记单单词的总数有N个，双单词的总数有M个，则有下面的公式<br><img src="https://img-blog.csdnimg.cn/20190228172528100.png" alt="具体例子"></p>
<h3 id="左右熵"><a href="#左右熵" class="headerlink" title="左右熵"></a>左右熵</h3><p>我们这里使用左右熵来衡量主要是想表示预选词的自由程度(4G上网卡为一个预选词），左右熵越大，表示这个词的左边右边的词换的越多，那么它就很有可能是一个单独的词。<br>我们这里的左右熵定义为(以左熵为例):<br><img src="https://img-blog.csdnimg.cn/20190228172807236.png" alt="左熵"><br>这里我们还是举一个具体的例子来理解它<br>假设4G上网卡左右有这么几种搭配<br>[买4G上网卡, 有4G上网卡，有4G上网卡， 丢4G上网卡]<br>那么4G上网卡的左熵为<br><img src="https://img-blog.csdnimg.cn/20190228172830315.png" alt="例子"><br>这里A = [买, 有, 丢]</p>
<blockquote>
<p>后面就是具体的实现了，这里的难点就在如何获得这些概率值，就博主看到的用法有：利用搜索引擎获取词汇共现率即p(x,y)、利用语料库获取各个词出现概率</p>
</blockquote>
<h2 id="最后我们只需要将这三步获得的情感词典进行整合就可以了"><a href="#最后我们只需要将这三步获得的情感词典进行整合就可以了" class="headerlink" title="最后我们只需要将这三步获得的情感词典进行整合就可以了"></a>最后我们只需要将这三步获得的情感词典进行整合就可以了</h2><p>参考文献：<br><a href="https://www.jianshu.com/p/e9313fd692ef">python3实现互信息和左右熵的新词发现</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>NLP</category>
        <category>情感分析</category>
      </categories>
      <tags>
        <tag>情感分析</tag>
        <tag>情感词典</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera Machine Learning 学习笔记（一）Introduction</title>
    <url>/2019/03/02/2019-03-02-Coursera%20Machine%20Learning%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89Introduction/</url>
    <content><![CDATA[<p>文章为博主学习Coursera上的Machine Learning课程的笔记，Coursera Machine Learning 学习笔记（一）Introduction</p>
<span id="more"></span>
<blockquote>
<p>文章为博主学习Coursera上的Machine Learning课程的笔记，来记录自己的学习过程，欢迎大家一起学习交流</p>
</blockquote>
<h1 id="01-Introduction"><a href="#01-Introduction" class="headerlink" title="01:Introduction"></a>01:Introduction</h1><h2 id="机器学习的定义"><a href="#机器学习的定义" class="headerlink" title="机器学习的定义"></a>机器学习的定义</h2><ul>
<li><p>Arthur Samuel(1959)<br>  <strong>Machine Learning:</strong>“Field of study that gives computers the ability to learn without being explicitly programmed”</p>
</li>
<li><p>Tom Michel(1999)<br>  <strong>Well posed learning problem:</strong>“A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”<br>  在下棋的例子中：</p>
</li>
</ul>
<ol>
<li>E经验为1000场下棋游戏</li>
<li>T任务为下棋</li>
<li>P评价准则为是否获胜</li>
</ol>
<ul>
<li><p>学习算法的类型<br>  。 有监督学习（Supervised learning）</p>
<pre><code>      Teach the computer how to do something, then let it use it;s new found knowledge to do it

      注：一般是有标注的训练集
</code></pre><p>  。无监督学习（Unsupervised learning）<br>  Let the computer learn how to do something, and use this to determine structure and patterns in data</p>
<pre><code>      注：一般是无标注训练集，使机器从中提取特征，常见算法为聚类
</code></pre><p>  。强化学习（Reinforcement learning）</p>
<p>  。推荐系统（Recommender systems）</p>
</li>
</ul>
<h3 id="有监督学习介绍"><a href="#有监督学习介绍" class="headerlink" title="有监督学习介绍"></a>有监督学习介绍</h3><h5 id="问题分类："><a href="#问题分类：" class="headerlink" title="问题分类："></a>问题分类：</h5><ul>
<li>预测问题<br>课程内拿房价预测作为示例：具体可以看课程内容<br>预测问题也叫回归问题，具有以下特征：</li>
</ul>
<ol>
<li>预测连续的输出</li>
<li>没有明显得离散划分</li>
</ol>
<ul>
<li>分类问题<br>课程内以肿瘤划分作为示例</li>
</ul>
<h3 id="无监督学习介绍"><a href="#无监督学习介绍" class="headerlink" title="无监督学习介绍"></a>无监督学习介绍</h3><p>在无监督学习里我们获得的是没有标注的数据，将这些数据划分成不同的数据簇</p>
<h5 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h5><p>具体应用示例：</p>
<ol>
<li>新闻划分</li>
<li>基因组排序</li>
<li>分布式计算机集群划分</li>
<li>社交网络划分</li>
<li>天文数据分析</li>
</ol>
]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Introduction</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera Machine Learning 学习笔记（二）Linear Regression</title>
    <url>/2019/03/02/2019-03-02-Coursera%20Machine%20Learning%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89Linear%20Regression/</url>
    <content><![CDATA[<p>文章为博主学习Coursera上的Machine Learning课程的笔记，Coursera Machine Learning 学习笔记（二）Linear Regression</p>
<span id="more"></span>
<blockquote>
<p>文章为博主学习Coursera上的Machine Learning课程的笔记，来记录自己的学习过程，欢迎大家一起学习交流</p>
</blockquote>
<h1 id="02：Linear-Regression"><a href="#02：Linear-Regression" class="headerlink" title="02：Linear Regression"></a>02：Linear Regression</h1><p>仍然以房价预测作为示例，具体示例仍需见课程内容。<br>符号含义：</p>
<ol>
<li>m 为数据集的大小</li>
<li>x’s为输入数据</li>
<li>y’s为对应的目标输出结果</li>
<li>(x,y)为所有训练数据</li>
<li>(x<sup>i</sup>, y<sup>i</sup>)为具体第i行数据，第i个训练数据</li>
</ol>
<p>假设函数h(x)，以一元线性回归为例：<br><img src="https://img-blog.csdnimg.cn/20190302112701595.png" alt="假设函数"></p>
<script type="math/tex; mode=display">\theta_0：截距  \theta_1：梯度</script><h5 id="Linear-regression-implementation（损失函数cost-function）"><a href="#Linear-regression-implementation（损失函数cost-function）" class="headerlink" title="Linear regression - implementation（损失函数cost function）"></a>Linear regression - implementation（损失函数cost function）</h5><p>计算由不同θ 取值带来的不同损失函数值，本质上是一个最小化问题：使下式取值最小</p>
<script type="math/tex; mode=display">Minimize ：(h_\theta(x)-y)^2</script><p>即可以看成下述式子：</p>
<script type="math/tex; mode=display">J(\theta_0,\theta_1) = \frac 1 {2m}\sum_1^m(h_\theta(x^{(i)})-y^{(i)})^2</script><script type="math/tex; mode=display">\frac1 m 是求平均\frac1 {2m}是为了数学计算方便</script><p>这个损失函数是均方误差，适用于多类回归问题，当然也可以有其他的损失函数。</p>
<h5 id="梯度下降算法（Gradient-descent-algorithm）"><a href="#梯度下降算法（Gradient-descent-algorithm）" class="headerlink" title="梯度下降算法（Gradient descent algorithm）"></a>梯度下降算法（Gradient descent algorithm）</h5><p><strong>目的：</strong> 使损失函数J最小</p>
<h6 id="工作方式"><a href="#工作方式" class="headerlink" title="工作方式"></a>工作方式</h6><ul>
<li>从随机初始化开始</li>
</ul>
<ol>
<li>对θ 随机赋值，可以为任何值</li>
<li>每次一点点改变θ，使J(θ)减小</li>
</ol>
<ul>
<li>每次沿着梯度下降最大的方向</li>
<li>重复上述操作直到达到局部最小值</li>
<li>从哪里开始的可能决定你到达哪个局部最优解<br><img src="https://img-blog.csdnimg.cn/2019030217133153.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNjc2MDMz,size_16,color_FFFFFF,t_70" alt="梯度下降"><br><strong>一个更正规的定义：</strong><br>做下述操作直到收敛：<br><img src="https://img-blog.csdnimg.cn/20190302171951356.png" alt="参数更新"><br>符号解释：</li>
</ul>
<ol>
<li><strong>:=</strong><br>表示赋值<br>NB a = b 是一个正确的断言</li>
<li>α (alpha)<br>学习率，控制参数更新的步长<ol>
<li>如果学习率过大，可能无法得到最优解，误差会增大</li>
<li>如果学习率过小，那么达到最优解需要非常多步，耗费很长时间</li>
</ol>
</li>
</ol>
<p>注： 参数的更新必须<strong>同步</strong>即需要一个中间变量保存之前的值，原因是二者的式子中包含了对方，一方的更新会导致第二方式子内值的变化。<br><img src="https://img-blog.csdnimg.cn/20190302173355106.png" alt="在这里插入图片描述"><br><strong>当我们达到局部最优解时：</strong></p>
<ol>
<li>后面部分的梯度为0</li>
<li>各参数值就保持不变了 </li>
</ol>
<h5 id="使用梯度下降的线性回归算法"><a href="#使用梯度下降的线性回归算法" class="headerlink" title="使用梯度下降的线性回归算法"></a>使用梯度下降的线性回归算法</h5><ul>
<li>将梯度下降算法应用到最小化损失函数J(θ)上</li>
</ul>
<script type="math/tex; mode=display">\frac{\partial} {\partial\theta_j}=\frac 1 {2m}\sum_1^m(h_\theta(x^{(i)})-y^{(i)})^2=\frac{\partial} {\partial\theta_j}\frac 1 {2m}\sum_1^m(\theta_0+\theta_1x^{(i)}-y^{(i)})^2</script><p>按照求导公式可以推出：</p>
<script type="math/tex; mode=display">j=0:\frac{\partial} {\partial\theta_0}J(\theta_0,\theta_1)=\frac1 m\sum_1^m(h_\theta(x^{(i)})-y^{(i)})</script><script type="math/tex; mode=display">j=1:\frac{\partial} {\partial\theta_1}J(\theta_0,\theta_1)=\frac1 m\sum_1^m(h_\theta(x^{(i)})-y^{(i)})*x^{(i)}</script><p>注：因为线性回归是一个凸函数，是一个碗形的图，所以会趋于局部最优解</p>
<ul>
<li>现在的这种梯度下降算法又叫Batch Gradient Descent 原因是每一次都遍历了整个数据集，后面会提到取数据集中的部分进行的Gradient Descent</li>
<li>线性回归也有正规方程求解，但其中矩阵运算当数据集过大时不宜使用，这时就可以使用梯度下降</li>
</ul>
<h5 id="数值求解的正规方程法"><a href="#数值求解的正规方程法" class="headerlink" title="数值求解的正规方程法"></a>数值求解的正规方程法</h5><ul>
<li>直接通过数值求解来避免繁琐的迭代过程，从数学上求解出min(J(θ))<br><strong>正规方程的优缺点：</strong><br><strong>优点：</strong><br>1.不需要学习率这个参数<br>2.对某些问题可以很快的解决<br><strong>缺点：</strong><br>会很复杂</li>
</ul>
<h5 id="面对数据量很大的时候"><a href="#面对数据量很大的时候" class="headerlink" title="面对数据量很大的时候"></a>面对数据量很大的时候</h5><p>这个时候就需要<strong>将数据向量化</strong>利用线性代数中矩阵运算来完成计算</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Linear Regression</tag>
      </tags>
  </entry>
  <entry>
    <title>Python数据分析-数据可视化</title>
    <url>/2020/01/03/2020-01-03-Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<p>本文将介绍使用Matplotlib工具，完成Python数据分析-数据可视化</p>
<span id="more"></span>
<h1 id="一-Matplotlib-基本概念"><a href="#一-Matplotlib-基本概念" class="headerlink" title="一. Matplotlib 基本概念"></a>一. Matplotlib 基本概念</h1><p>Matplotlib是python的一个数据可视化工具库。</p>
<p>特点：专门用于开发2D图表(包括3D图表)， 操作简单。</p>
<p>可视化是在整个数据挖掘的关键辅助工具，可以清晰的理解数据，从而调整我们的分析方法。</p>
<h1 id="二-Matplotlib三层结构"><a href="#二-Matplotlib三层结构" class="headerlink" title="二. Matplotlib三层结构"></a>二. Matplotlib三层结构</h1><p><img src="https://img-blog.csdnimg.cn/20190313235406342.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH,size_16,color_FFFFFF,t_70" alt="三层结构"></p>
<h1 id="三-Matplotlib-基本使用"><a href="#三-Matplotlib-基本使用" class="headerlink" title="三. Matplotlib 基本使用"></a>三. Matplotlib 基本使用</h1><h2 id="1-折线图"><a href="#1-折线图" class="headerlink" title="1. 折线图"></a>1. 折线图</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"># 图形显示设置</span><br><span class="line">%matplotlib inline   </span><br><span class="line"> </span><br><span class="line"># 绘制画布-容器层  figsize: 画布长宽属性   dpi: 图象的清晰度</span><br><span class="line">plt.figure(figsize=(16,8), dpi=60)</span><br><span class="line"> </span><br><span class="line"># 绘制折线图-图象层</span><br><span class="line">plt.plot([1,2,3,4,5,6], [22,19,18,25,27,19])</span><br><span class="line"> </span><br><span class="line"># 显示图象</span><br><span class="line"># plt.show()</span><br><span class="line"> </span><br><span class="line"># 保存图象 -注：plt.show()会释放figure资源，保存图片需要将plt.show()注释掉</span><br><span class="line"># 图片的保存路径 -- </span><br><span class="line">plt.savefig(&quot;plot.png&quot;)</span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdn.net/20180917191105231?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="在这里插入图片描述"></p>
<h2 id="2-绘制多条折线图"><a href="#2-绘制多条折线图" class="headerlink" title="2. 绘制多条折线图"></a>2. 绘制多条折线图</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import random</span><br><span class="line">%matplotlib inline</span><br><span class="line"># 中文显示问题-- 下载中文字体，安装字体-修改配置文件下面手动修改配置</span><br><span class="line"># from pylab import mpl</span><br><span class="line"># mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]</span><br><span class="line"># mpl.rcParams[&quot;axes.unicode_minus&quot;] = False # 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span><br><span class="line"> </span><br><span class="line"># 准备数据</span><br><span class="line">x = range(60)</span><br><span class="line">y_sh = [random.uniform(26,31) for i in x]</span><br><span class="line">y_bj = [random.uniform(27, 35) for i in x]</span><br><span class="line"> </span><br><span class="line"># 创建画布</span><br><span class="line">plt.figure(figsize=(16,8), dpi=60)</span><br><span class="line"> </span><br><span class="line"># 同一坐标内--绘制多条折线图  （新增）</span><br><span class="line">plt.plot(x, y_sh, label=&quot;sh&quot;)</span><br><span class="line">plt.plot(x, y_bj, label=&quot;bj&quot;, linestyle=&quot;--&quot;, color=&quot;y&quot;)  # 线条颜色，线条样式设置 见下图</span><br><span class="line"> </span><br><span class="line"># 自定义x, y轴 刻度 &amp; 刻度标签 (新增)</span><br><span class="line">x_ticks = range(0, 60, 5)</span><br><span class="line">y_ticks = range(20, 40, 5)</span><br><span class="line"> </span><br><span class="line">x_ticks_label = [&quot;11点&#123;&#125;分&quot;.format(i) for i in x_ticks]</span><br><span class="line"> </span><br><span class="line">plt.xticks(x_ticks, x_ticks_label)</span><br><span class="line">plt.yticks(y_ticks)</span><br><span class="line"> </span><br><span class="line"># 添加辅助描述信息-- x，y轴标签 &amp; 图形标题</span><br><span class="line">plt.xlabel(&quot;时间&quot;)</span><br><span class="line">plt.ylabel(&quot;温度&quot;)</span><br><span class="line"> </span><br><span class="line">plt.title(&quot;两地同一时间温度变化图&quot;)</span><br><span class="line"> </span><br><span class="line"># 添加网格线 - alpha:透明度   （新增）</span><br><span class="line">plt.grid(True, linestyle=&quot;--&quot;, alpha=0.6)</span><br><span class="line"> </span><br><span class="line"># 显示图例 -- loc：位置设置,详见下图  （新增）</span><br><span class="line">plt.legend(loc=&quot;best&quot;)</span><br><span class="line"> </span><br><span class="line"># 显示图象</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdn.net/20180917235044993?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="在这里插入图片描述"><br><strong>附参数表:</strong><br><img src="https://img-blog.csdn.net/20180917235125313?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20190310015842874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="3-绘制多个坐标系-—-plt-subplots"><a href="#3-绘制多个坐标系-—-plt-subplots" class="headerlink" title="3. 绘制多个坐标系 — plt.subplots"></a>3. 绘制多个坐标系 — plt.subplots</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import random</span><br><span class="line">%matplotlib inline</span><br><span class="line"># 中文显示问题--下面手动修改配置 </span><br><span class="line">from pylab import mpl</span><br><span class="line">mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]</span><br><span class="line">mpl.rcParams[&quot;axes.unicode_minus&quot;] = False</span><br><span class="line"> </span><br><span class="line"># 准备x,y轴数据</span><br><span class="line">x = range(60)</span><br><span class="line">y_sh = [random.uniform(15, 18) for i in x ]</span><br><span class="line">y_bj = [random.uniform(5, 12) for i in x ]</span><br><span class="line"> </span><br><span class="line"># 创建画布--多个坐标轴, 绘制折线图</span><br><span class="line">fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8), dpi=100)</span><br><span class="line"># Returns:  fig: 图对象    ax: 坐标轴对象列表</span><br><span class="line">axes[0].plot(x, y_sh, label=&#x27;上海&#x27;)</span><br><span class="line">axes[1].plot(x, y_bj, label=&#x27;北京&#x27;, color=&#x27;r&#x27;, linestyle=&#x27;--&#x27;)</span><br><span class="line"> </span><br><span class="line"># 显示图例/坐标轴刻度/网格线</span><br><span class="line">axes[0].legend()</span><br><span class="line">axes[1].legend()</span><br><span class="line"> </span><br><span class="line">x_ticks_label = [&#x27;11点&#123;&#125;分&#x27;.format(i) for i in x]</span><br><span class="line">y_ticks = range(40)</span><br><span class="line">axes[0].set_xticks(x[::5], x_ticks_label[::5])</span><br><span class="line">axes[0].set_yticks(y_ticks[::5])</span><br><span class="line">axes[1].set_xticks(x[::5], x_ticks_label[::5])</span><br><span class="line">axes[1].set_yticks(y_ticks[::5])</span><br><span class="line"> </span><br><span class="line">axes[0].grid(True, linestyle=&#x27;--&#x27;, alpha=0.5)</span><br><span class="line">axes[1].grid(True, linestyle=&#x27;--&#x27;, alpha=0.5)</span><br><span class="line"> </span><br><span class="line"># 添加 标题/坐标轴描述信息</span><br><span class="line">axes[0].set_title(&#x27;上海11点0分到12点之间的温度变化图&#x27;)</span><br><span class="line">axes[0].set_xlabel(&quot;时间&quot;)</span><br><span class="line">axes[0].set_ylabel(&quot;温度&quot;)</span><br><span class="line"> </span><br><span class="line">axes[1].set_title(&#x27;北京11点0分到12点之间的温度变化图&#x27;)</span><br><span class="line">axes[1].set_xlabel(&#x27;时间&#x27;)</span><br><span class="line">axes[1].set_ylabel(&#x27;温度&#x27;)</span><br><span class="line"> </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="4-绘制sin-函数图像-—-plot"><a href="#4-绘制sin-函数图像-—-plot" class="headerlink" title="4. 绘制sin()函数图像 — plot"></a>4. 绘制sin()函数图像 — plot</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 准备数据</span><br><span class="line">import numpy as np</span><br><span class="line">x = np.linspace(-10, 10, 1000)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"> </span><br><span class="line"># 创建画布，绘制图像，显示图像</span><br><span class="line">plt.figure(figsize=(10, 1), dpi=100)</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.grid(linestyle=&#x27;--&#x27;, alpha=0.5)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/2019031201165850.png" alt="在这里插入图片描述"></p>
<h2 id="5-散点图-—-scatter"><a href="#5-散点图-—-scatter" class="headerlink" title="5. 散点图 — scatter"></a>5. 散点图 — scatter</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># -- 案例： 探究房屋面积和房屋价格的关系</span><br><span class="line">from pylab import mpl          # 中文显示问题--下面手动修改配置 </span><br><span class="line">mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]</span><br><span class="line">mpl.rcParams[&quot;axes.unicode_minus&quot;] = False</span><br><span class="line"># 准备数据</span><br><span class="line">x = [225.98, 247.07, 253.14, 457.85, 241.58, 301.01,  20.67, 288.64,</span><br><span class="line">       163.56, 120.06, 207.83, 342.75, 147.9 ,  53.06, 224.72,  29.51,</span><br><span class="line">        21.61, 483.21, 245.25, 399.25, 343.35]</span><br><span class="line">y = [196.63, 203.88, 210.75, 372.74, 202.41, 247.61,  24.9 , 239.34,</span><br><span class="line">       140.32, 104.15, 176.84, 288.23, 128.79,  49.64, 191.74,  33.1 ,</span><br><span class="line">        30.74, 400.02, 205.35, 330.64, 283.45]</span><br><span class="line"> </span><br><span class="line"># 创建画布  -- 绘制散点图 -- 显示图像</span><br><span class="line">plt.figure(figsize=(20,8), dpi=100)</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line"> </span><br><span class="line">plt.title(&#x27;房屋面积和房屋价格的关系--案例测试&#x27;)</span><br><span class="line">plt.xlabel(&#x27;面积&#x27;)</span><br><span class="line">plt.ylabel(&#x27;价格&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190312012238645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="6-柱状图-—-bar"><a href="#6-柱状图-—-bar" class="headerlink" title="6. 柱状图 — bar"></a>6. 柱状图 — bar</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 准备数据</span><br><span class="line">movie_name = [&#x27;雷神3：诸神黄昏&#x27;,&#x27;正义联盟&#x27;,&#x27;东方快车谋杀案&#x27;,&#x27;寻梦环游记&#x27;,&#x27;全球风暴&#x27;,&#x27;降魔传&#x27;,&#x27;追捕&#x27;,&#x27;七十七天&#x27;,&#x27;密战&#x27;,&#x27;狂兽&#x27;,&#x27;其它&#x27;]</span><br><span class="line">y = [73853,57767,22354,15969,14839,8725,8716,8318,7916,6764,52222]</span><br><span class="line">x = range(len(movie_name))</span><br><span class="line"> </span><br><span class="line"># 创建画布，绘制柱状图，添加标题和格线，显示图像</span><br><span class="line">plt.figure(figsize=(18, 6), dpi=80)</span><br><span class="line">plt.bar(x, y, width=0.5, color=[&#x27;b&#x27;,&#x27;r&#x27;,&#x27;g&#x27;,&#x27;y&#x27;,&#x27;c&#x27;,&#x27;m&#x27;,&#x27;y&#x27;,&#x27;k&#x27;,&#x27;c&#x27;,&#x27;g&#x27;,&#x27;m&#x27;])</span><br><span class="line"> </span><br><span class="line">plt.title(&quot;电影票房收入对比&quot;)</span><br><span class="line">plt.xticks(x, movie_name)</span><br><span class="line">plt.grid(linestyle=&#x27;--&#x27;, alpha=0.5)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190312014545814.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="7-柱状图-—-多个指标对比"><a href="#7-柱状图-—-多个指标对比" class="headerlink" title="7. 柱状图 — 多个指标对比"></a>7. 柱状图 — 多个指标对比</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 准备数据</span><br><span class="line">movie_name = [&#x27;雷神3：诸神黄昏&#x27;,&#x27;正义联盟&#x27;,&#x27;寻梦环游记&#x27;]</span><br><span class="line">first_day = [10587.6,10062.5,1275.7]</span><br><span class="line">first_weekend=[36224.9,34479.6,11830]</span><br><span class="line">x = range(len(movie_name))</span><br><span class="line"> </span><br><span class="line"># 创建画布，绘制柱状图，添加标题/坐标轴刻度标签/网格线/示例， 显示图像</span><br><span class="line">plt.figure(figsize=(10, 5), dpi=80)</span><br><span class="line">plt.bar(x, first_day, width=0.2, label=&quot;首日票房&quot;)</span><br><span class="line">plt.bar([i+0.2 for i in x], first_weekend, width=0.2, label=&quot;首周票房&quot;)</span><br><span class="line"> </span><br><span class="line">plt.title(&quot;电影首日和首周的票房对比&quot;)</span><br><span class="line">plt.xticks([i+0.1 for i in x], movie_name)     # 修改x轴刻度显示</span><br><span class="line">plt.grid(linestyle=&quot;--&quot;, alpha=0.5)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190312020011216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="8-直方图-—-hist"><a href="#8-直方图-—-hist" class="headerlink" title="8 直方图 — hist"></a>8 直方图 — hist</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 准备数据</span><br><span class="line">time = [131,  98, 125, 131, 124, 139, 131, 117, 128, 108, 135, 138, 131, 102, 107, 114, 119, 128, 121, 142, 127, 130, 124, 101, 110, 116, 117, 110, 128, 128, 115,  99, 136, 126, 134,  95, 138, 117, 111,78, 132, 124, 113, 150, 110, 117,  86,  95, 144, 105, 126, 130,126, 130, 126, 116, 123, 106, 112, 138, 123,  86, 101,  99, 136,123, 117, 119, 105, 137, 123, 128, 125, 104, 109, 134, 125, 127,105, 120, 107, 129, 116, 108, 132, 103, 136, 118, 102, 120, 114,105, 115, 132, 145, 119, 121, 112, 139, 125, 138, 109, 132, 134,156, 106, 117, 127, 144, 139, 139, 119, 140,  83, 110, 102,123,107, 143, 115, 136, 118, 139, 123, 112, 118, 125, 109, 119, 133,112, 114, 122, 109, 106, 123, 116, 131, 127, 115, 118, 112, 135,115, 146, 137, 116, 103, 144,  83, 123, 111, 110, 111, 100, 154,136, 100, 118, 119, 133, 134, 106, 129, 126, 110, 111, 109, 141,120, 117, 106, 149, 122, 122, 110, 118, 127, 121, 114, 125, 126,114, 140, 103, 130, 141, 117, 106, 114, 121, 114, 133, 137,  92,121, 112, 146,  97, 137, 105,  98, 117, 112,  81,  97, 139, 113,134, 106, 144, 110, 137, 137, 111, 104, 117, 100, 111, 101, 110,105, 129, 137, 112, 120, 113, 133, 112,  83,  94, 146, 133, 101,131, 116, 111,  84, 137, 115, 122, 106, 144, 109, 123, 116, 111,111, 133, 150]</span><br><span class="line"> </span><br><span class="line"># 创建画布， 绘制直方图， 添加标题/坐标轴刻度标签/网格线</span><br><span class="line">plt.figure(figsize=(20, 8), dpi=80)</span><br><span class="line">distance = 2</span><br><span class="line">group_num = int((max(time)-min(time)) / distance)</span><br><span class="line">plt.hist(time, bins=group_num)</span><br><span class="line"> </span><br><span class="line">plt.title(&quot;电影时长分布状况&quot;)</span><br><span class="line">plt.xticks(range(min(time), max(time))[::2])</span><br><span class="line">plt.xlabel(&quot;电影时长&quot;)</span><br><span class="line">plt.ylabel(&quot;数量&quot;)</span><br><span class="line">plt.grid(linestyle=&quot;--&quot;, alpha=0.5)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190313233637810.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="9-饼图-—-pie"><a href="#9-饼图-—-pie" class="headerlink" title="9 饼图 — pie"></a>9 饼图 — pie</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 准备数据   -- 案例：电影的排片占比</span><br><span class="line">movie_name = [&#x27;雷神3：诸神黄昏&#x27;,&#x27;正义联盟&#x27;,&#x27;东方快车谋杀案&#x27;,&#x27;寻梦环游记&#x27;,&#x27;全球风暴&#x27;,&#x27;降魔传&#x27;,&#x27;追捕&#x27;,&#x27;七十七天&#x27;,&#x27;密战&#x27;,&#x27;狂兽&#x27;,&#x27;其它&#x27;]</span><br><span class="line">place_count = [60605,54546,45819,28243,13270,9945,7679,6799,6101,4621,20105]</span><br><span class="line"> </span><br><span class="line"># 创建画布，绘制饼图，添加标题/坐标轴刻度标签</span><br><span class="line">plt.figure(figsize=(18, 6), dpi=80)</span><br><span class="line">plt.pie(place_count, labels=movie_name, autopct=&quot;%1.2f%%&quot;)</span><br><span class="line">plt.axis(&quot;equal&quot;)          #  坐标轴长宽相等，保证饼图成圆形</span><br><span class="line"> </span><br><span class="line">plt.title(&quot;电影的排片占比&quot;)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190313235128167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JlZnJhaW5fX1dH,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="10-VENN-韦恩图"><a href="#10-VENN-韦恩图" class="headerlink" title="10.VENN 韦恩图"></a>10.VENN 韦恩图</h2><p><strong>需要先下载matplotlib_venn</strong></p>
<h3 id="10-1-具有2个分组的基本的维恩图"><a href="#10-1-具有2个分组的基本的维恩图" class="headerlink" title="10.1 具有2个分组的基本的维恩图"></a>10.1 具有2个分组的基本的维恩图</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#_*_coding:utf-8_*_</span><br><span class="line"># author    : jmx</span><br><span class="line"># create    : 19-12-16 上午11:08</span><br><span class="line"># filename  : venn.py</span><br><span class="line"># IDE   : PyCharm</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib_venn import venn2</span><br><span class="line"></span><br><span class="line"># 第一种方法，10，5为两组的大小，2为两组交叉大小;</span><br><span class="line"># set_labels为组名</span><br><span class="line"># venn2(subsets = (10, 5, 2), set_labels = (&#x27;Group A&#x27;, &#x27;Group B&#x27;))</span><br><span class="line"># 设置两组数据为ABCD和DEF</span><br><span class="line">venn2([set([&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;]), set([&#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;])])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vbHVtaW5pb3VzL2FydGljbGVfcGljdHVyZV93YXJlaG91c2UvcmF3L21hc3Rlci9QeXRob24tU3R1ZHktTm90ZXMvVkVOTiUyMERJQUdSQU0vb3V0cHV0XzRfMC5wbmc?x-oss-process=image/format,png" alt="在这里插入图片描述"></p>
<h3 id="10-2-具有3个组的基本维恩图"><a href="#10-2-具有3个组的基本维恩图" class="headerlink" title="10.2 具有3个组的基本维恩图"></a>10.2 具有3个组的基本维恩图</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#_*_coding:utf-8_*_</span><br><span class="line"># author    : jmx</span><br><span class="line"># create    : 19-12-16 上午11:08</span><br><span class="line"># filename  : venn.py</span><br><span class="line"># IDE   : PyCharm</span><br><span class="line"># Import the library</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib_venn import venn3</span><br><span class="line"> </span><br><span class="line"># Make the diagram</span><br><span class="line">venn3(subsets = (10, 8, 22, 6,9,4,2)) # 通过直接设置各部分数据来配置韦恩图</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vbHVtaW5pb3VzL2FydGljbGVfcGljdHVyZV93YXJlaG91c2UvcmF3L21hc3Rlci9QeXRob24tU3R1ZHktTm90ZXMvVkVOTiUyMERJQUdSQU0vb3V0cHV0XzZfMC5wbmc?x-oss-process=image/format,png" alt="在这里插入图片描述"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 设置三组ABCD、DEF、ADG</span><br><span class="line">venn3([set([&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;]), set([&#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;]), set([&#x27;A&#x27;, &#x27;D&#x27;, &#x27;G&#x27;,&#x27;F&#x27;])]) # 设置数据来配置韦恩图</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vbHVtaW5pb3VzL2FydGljbGVfcGljdHVyZV93YXJlaG91c2UvcmF3L21hc3Rlci9QeXRob24tU3R1ZHktTm90ZXMvVkVOTiUyMERJQUdSQU0vb3V0cHV0XzdfMC5wbmc?x-oss-process=image/format,png" alt="在这里插入图片描述"></p>
<h3 id="10-3-自定义维恩图"><a href="#10-3-自定义维恩图" class="headerlink" title="10.3 自定义维恩图"></a>10.3 自定义维恩图</h3><ol>
<li>自定义标签</li>
<li>自定义维恩图上圆的线条</li>
<li>自定义维恩图上的圆</li>
</ol>
<p><strong>自定义标签</strong></p>
<ul>
<li>get_label_by_id 可查看其源代码 表示分类里不同部分<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#_*_coding:utf-8_*_</span><br><span class="line"># author    : jmx</span><br><span class="line"># create    : 19-12-16 上午11:08</span><br><span class="line"># filename  : venn.py</span><br><span class="line"># IDE   : PyCharm</span><br><span class="line">## Venn上的自定义标签 Custom label on Venn</span><br><span class="line"># Import the library</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib_venn import venn3</span><br><span class="line">from matplotlib_venn import venn3_circles</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Custom text labels: change the label of group A</span><br><span class="line">v=venn3(subsets = (10, 8, 22, 6,9,4,2), set_labels = (&#x27;Group A&#x27;, &#x27;Group B&#x27;, &#x27;Group C&#x27;))</span><br><span class="line"># 单独改变A的标签</span><br><span class="line">v.get_label_by_id(&#x27;A&#x27;).set_text(&#x27;My Favourite group!&#x27;)</span><br></pre></td></tr></table></figure>
<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vbHVtaW5pb3VzL2FydGljbGVfcGljdHVyZV93YXJlaG91c2UvcmF3L21hc3Rlci9QeXRob24tU3R1ZHktTm90ZXMvVkVOTiUyMERJQUdSQU0vb3V0cHV0XzlfMC5wbmc?x-oss-process=image/format,png" alt="在这里插入图片描述"><br><strong>自定义维恩图上圆的线条</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#_*_coding:utf-8_*_</span><br><span class="line"># author    : jmx</span><br><span class="line"># create    : 19-12-16 上午11:08</span><br><span class="line"># filename  : venn.py</span><br><span class="line"># IDE   : PyCharm</span><br><span class="line">## 自定义维恩图上圆的线条 Custom Circles lines on Venn</span><br><span class="line"># Line style: can be &#x27;dashed&#x27; or &#x27;dotted&#x27; for example</span><br><span class="line"># 设置维恩图</span><br><span class="line">v = venn3(subsets = (10, 8, 22, 6,9,4,2), set_labels = (&#x27;Group A&#x27;, &#x27;Group B&#x27;, &#x27;Group C&#x27;))</span><br><span class="line"># 画圆，linestyle线条类型，linewith线宽，color线条颜色</span><br><span class="line">c = venn3_circles(subsets = (10, 8, 22, 6,9,4,2), linestyle=&#x27;dashed&#x27;, linewidth=1, color=&quot;grey&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vbHVtaW5pb3VzL2FydGljbGVfcGljdHVyZV93YXJlaG91c2UvcmF3L21hc3Rlci9QeXRob24tU3R1ZHktTm90ZXMvVkVOTiUyMERJQUdSQU0vb3V0cHV0XzEwXzAucG5n?x-oss-process=image/format,png" alt="在这里插入图片描述"><br><strong>自定义维恩图上的圆</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#_*_coding:utf-8_*_</span><br><span class="line"># author    : jmx</span><br><span class="line"># create    : 19-12-16 上午11:08</span><br><span class="line"># filename  : venn.py</span><br><span class="line"># IDE   : PyCharm</span><br><span class="line">## 自定义维恩图上的圆 Custom a circle on Venn</span><br><span class="line"># Change one group only</span><br><span class="line">v=venn3(subsets = (10, 8, 22, 6,9,4,2), set_labels = (&#x27;Group A&#x27;, &#x27;Group B&#x27;, &#x27;Group C&#x27;))</span><br><span class="line">c=venn3_circles(subsets = (10, 8, 22, 6,9,4,2), linestyle=&#x27;dashed&#x27;, linewidth=1, color=&quot;grey&quot;)</span><br><span class="line"># 设置第一个圆的线宽</span><br><span class="line">c[0].set_lw(8.0)</span><br><span class="line"># 设置第一个圆的线形</span><br><span class="line">c[0].set_ls(&#x27;dotted&#x27;)</span><br><span class="line"># 设置第一个圆的填充颜色</span><br><span class="line">c[0].set_color(&#x27;skyblue&#x27;)</span><br><span class="line"> </span><br><span class="line"># Color</span><br><span class="line"># id号</span><br><span class="line"># 如ABC三个簇，010代表非A和B和非C,100代表A和非B和非C</span><br><span class="line"># 设置透明度</span><br><span class="line">v.get_patch_by_id(&#x27;011&#x27;).set_alpha(1.0)</span><br><span class="line"># 设置颜色</span><br><span class="line">v.get_patch_by_id(&#x27;011&#x27;).set_color(&#x27;red&#x27;)</span><br><span class="line"># 打印id号</span><br><span class="line">#v.id2idx</span><br></pre></td></tr></table></figure>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vbHVtaW5pb3VzL2FydGljbGVfcGljdHVyZV93YXJlaG91c2UvcmF3L21hc3Rlci9QeXRob24tU3R1ZHktTm90ZXMvVkVOTiUyMERJQUdSQU0vb3V0cHV0XzExXzAucG5n?x-oss-process=image/format,png" alt="在这里插入图片描述"></p>
<h3 id="10-4-修改韦恩图数值"><a href="#10-4-修改韦恩图数值" class="headerlink" title="10.4 修改韦恩图数值"></a>10.4 修改韦恩图数值</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#_*_coding:utf-8_*_</span><br><span class="line"># author    : jmx</span><br><span class="line"># create    : 19-12-16 上午11:08</span><br><span class="line"># filename  : venn.py</span><br><span class="line"># IDE   : PyCharm</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from matplotlib_venn import venn3, venn3_circles</span><br><span class="line">import matplotlib.font_manager as fm</span><br><span class="line">from pathlib import Path</span><br><span class="line">def venn(train_filename=&#x27;biaozhuData/generate_data/train/pkuverb.txt&#x27;, val_filename=&#x27;biaozhuData/generate_data_2/valid/pkuverb.txt&#x27;, test_filename=&#x27;biaozhuData/generate_data_2/test/pkuverb.txt&#x27;):</span><br><span class="line">	&#x27;&#x27;&#x27;</span><br><span class="line">	训练集、验证集、测试集 数据分布的韦恩图</span><br><span class="line">	:param train_filename:</span><br><span class="line">	:param val_filename:</span><br><span class="line">	:param test_filename:</span><br><span class="line">	:return:</span><br><span class="line">	&#x27;&#x27;&#x27;</span><br><span class="line">	path = Path(train_filename)</span><br><span class="line">	set1 = set(open(test_filename, encoding=&#x27;utf-8&#x27;).readlines())</span><br><span class="line">	set2 = set(open(val_filename, encoding=&#x27;utf-8&#x27;).readlines())</span><br><span class="line">	set3 = set(open(train_filename, encoding=&#x27;utf-8&#x27;).readlines())</span><br><span class="line"></span><br><span class="line">	set_len1 = len(set1)</span><br><span class="line">	set_len2 = len(set2)</span><br><span class="line">	set_len3 = len(set3)</span><br><span class="line"></span><br><span class="line">	v = venn3([set1, set2, set3], (&#x27;test&#x27;, &#x27;valid&#x27;, &#x27;train&#x27;))</span><br><span class="line">	a = v.get_label_by_id(&#x27;100&#x27;).get_text()</span><br><span class="line">	b = v.get_label_by_id(&#x27;010&#x27;).get_text()</span><br><span class="line">	c = v.get_label_by_id(&#x27;001&#x27;).get_text()</span><br><span class="line"></span><br><span class="line">	a = str(round(int(a) / set_len1, 3)) + &#x27; &#x27; + a</span><br><span class="line">	b = str(round(int(b) / set_len2, 3)) + &#x27; &#x27; + b</span><br><span class="line">	c = str(round(int(c) / set_len3, 3)) + &#x27; &#x27; + c</span><br><span class="line"></span><br><span class="line">	v.get_label_by_id(&#x27;100&#x27;).set_text(a)</span><br><span class="line">	v.get_label_by_id(&#x27;010&#x27;).set_text(b)</span><br><span class="line">	v.get_label_by_id(&#x27;001&#x27;).set_text(c)</span><br><span class="line">	plt.title(name[path.stem]+&#x27;集合关系&#x27;, fontproperties=myfont)</span><br><span class="line">	sfname = path.name.replace(path.suffix, &#x27;.png&#x27;)</span><br><span class="line">	savepath = Path(venn_savedir)/sfname</span><br><span class="line">	#plt.show()</span><br><span class="line">	plt.savefig(savepath)</span><br><span class="line">	plt.close()</span><br></pre></td></tr></table></figure>
<h1 id="四-Matplotlib-中文无法显示问题"><a href="#四-Matplotlib-中文无法显示问题" class="headerlink" title="四. Matplotlib 中文无法显示问题"></a>四. Matplotlib 中文无法显示问题</h1><ol>
<li>windows下：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">plt.rcParams[&#x27;font.sans-serif&#x27;]=[&#x27;SimHei&#x27;] #用来正常显示中文标签</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import random</span><br><span class="line">%matplotlib inline</span><br><span class="line"># 中文显示问题--下面手动修改配置 </span><br><span class="line">from pylab import mpl</span><br><span class="line">mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]</span><br><span class="line">mpl.rcParams[&quot;axes.unicode_minus&quot;] = False</span><br></pre></td></tr></table></figure>
<ol>
<li>Ubuntu/LInux下</li>
</ol>
<p><a href="https://www.cnblogs.com/panlq/p/9270826.html">Ubuntu解决matplotlib中文无法显示</a></p>
<p>其实这些乱码问题，只是路径等配置问题，上述只是修改默认的配置，可以通过指定字体路径等来解决。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">myfont = fm.FontProperties(fname=r&#x27;1031Competition/font/simsun.ttc&#x27;)  # 设置字体</span><br><span class="line">……</span><br><span class="line">plt.xlabel(&#x27;短语类型&#x27;, fontproperties=myfont)</span><br><span class="line">plt.ylabel(&#x27;比例&#x27;, fontproperties=myfont)</span><br><span class="line">plt.legend(loc=&#x27;upper right&#x27;)</span><br><span class="line">plt.savefig(&#x27;test.png&#x27;)</span><br></pre></td></tr></table></figure>
<p><strong>参考文章</strong><br><a href="https://blog.csdn.net/refrain__wg/article/details/82747254">Matplotlib 数据可视化-基本使用教程</a><br><a href="https://blog.csdn.net/LuohenYJ/article/details/103091081">python基于matplotlib_venn实现维恩图的绘制</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>数据分析</category>
        <category>数据可视化</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 多卡训练</title>
    <url>/2021/09/12/2021-09-12-Pytorch%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>本文将介绍Pytorch 多卡训练的原理及实现。多卡训练流程一般如下：</p>
<ol>
<li>指定主机节点</li>
<li>主机节点划分数据，一个batch数据平均分到每个机器上</li>
<li>模型从主机拷贝到各个机器</li>
<li>每个机器进行前向传播</li>
<li>每个机器计算loss损失</li>
<li>主机收集所有loss结果，进行参数更新</li>
<li>将更新后参数模型拷贝给各个机器</li>
</ol>
<span id="more"></span>
<h1 id="Pytorch-多卡训练"><a href="#Pytorch-多卡训练" class="headerlink" title="Pytorch 多卡训练"></a>Pytorch 多卡训练</h1><h2 id="一、多卡训练原理"><a href="#一、多卡训练原理" class="headerlink" title="一、多卡训练原理"></a>一、多卡训练原理</h2><p>多卡训练流程一般如下：</p>
<ol>
<li>指定主机节点</li>
<li>主机节点划分数据，一个batch数据平均分到每个机器上</li>
<li>模型从主机拷贝到各个机器</li>
<li>每个机器进行前向传播</li>
<li>每个机器计算loss损失</li>
<li>主机收集所有loss结果，进行参数更新</li>
<li>将更新后参数模型拷贝给各个机器</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/img_convert/1665788acfe3757d493b3d82422035c1.png" alt="image"></p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/bffacf11040884149347a428d6f63260.png" alt="image"></p>
<h2 id="二、单机多卡训练"><a href="#二、单机多卡训练" class="headerlink" title="二、单机多卡训练"></a>二、单机多卡训练</h2><p>使用<strong>torch.nn.DataParallel</strong>(module, device_ids)模块，module为模型，device_ids为并行的GPU id列表</p>
<p>使用方式：将模型调用该接口执行操作</p>
<p><code>model = torch.nn.DataParallel(model)</code></p>
<p>示例：我们假设模型输入为(32, input_dim)，这里的 32 表示batch_size，模型输出为(32, output_dim)，使用 4 个GPU训练。nn.DataParallel起到的作用是将这 32 个样本拆成 4 份，发送给 4 个GPU 分别做 forward，然后生成 4 个大小为(8, output_dim)的输出，然后再将这 4 个输出都收集到cuda:0上并合并成(32, output_dim)。</p>
<p>可以看出，nn.DataParallel没有改变模型的输入输出，因此其他部分的代码不需要做任何更改，非常方便。但弊端是，后续的loss计算只会在cuda:0上进行，没法并行，因此会导致负载不均衡的问题。</p>
<p>通过在模型内置loss计算可以解决上述负载不均衡的情况，最后所得loss进行取平均。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Net:</span><br><span class="line">    def __init__(self,...):</span><br><span class="line">        # code</span><br><span class="line">    </span><br><span class="line">    def forward(self, inputs, labels=None)</span><br><span class="line">        # outputs = fct(inputs)</span><br><span class="line">        # loss_fct = ...</span><br><span class="line">        if labels is not None:</span><br><span class="line">            loss = loss_fct(outputs, labels)  # 在训练模型时直接将labels传入模型，在forward过程中计算loss</span><br><span class="line">            return loss</span><br><span class="line">        else:</span><br><span class="line">            return outputs</span><br></pre></td></tr></table></figure>
<p>按照我们上面提到的模型并行逻辑，在每个GPU上会计算出一个loss，这些loss会被收集到cuda:0上并合并成长度为 4 的张量。这个时候在做backward的之前，必须对将这个loss张量合并成一个标量，一般直接取mean就可以。这在Pytorch官方文档nn.DataParallel函数中有提到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">When module returns a scalar (i.e., 0-dimensional tensor) in forward(), this wrapper will return a vector of length equal to number of devices used in data parallelism, containing the result from each device.</span><br></pre></td></tr></table></figure>
<h2 id="三、多机多卡训练"><a href="#三、多机多卡训练" class="headerlink" title="三、多机多卡训练"></a>三、多机多卡训练</h2><p><strong>该方式也可以实现单机多卡</strong></p>
<p>使用<strong>torch.nn.parallel.DistributedDataParallel</strong>和<strong>torch.utils.data.distributed.DistributedSampler</strong>结合多进程实现。</p>
<ol>
<li><p>从一开始就会启动多个进程(进程数小于等于GPU数)，每个进程独享一个GPU，每个进程都会独立地执行代码。这意味着每个进程都独立地初始化模型、训练，当然，在每次迭代过程中会通过进程间通信共享梯度，整合梯度，然后独立地更新参数。</p>
</li>
<li><p>每个进程都会初始化一份训练数据集，当然它们会使用数据集中的不同记录做训练，这相当于同样的模型喂进去不同的数据做训练，也就是所谓的数据并行。这是通过<strong>torch.utils.data.distributed.DistributedSampler</strong>函数实现的，不过逻辑上也不难想到，只要做一下数据partition，不同进程拿到不同的parition就可以了，官方有一个简单的demo，感兴趣的可以看一下代码实现：Distributed Training</p>
</li>
<li><p>进程通过local_rank变量来标识自己，local_rank为0的为master，其他是slave。这个变量是torch.distributed包帮我们创建的，使用方法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import argparse  # 必须引入 argparse 包</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;--local_rank&quot;, type=int, default=-1)</span><br><span class="line">args = parser.parse_args()</span><br></pre></td></tr></table></figure>
<p>必须以如下方式运行代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m torch.distributed.launch --nproc_per_node=2 --nnodes=1 train.py</span><br></pre></td></tr></table></figure>
<p>这样的话，torch.distributed.launch就以命令行参数的方式将args.local_rank变量注入到每个进程中，每个进程得到的变量值都不相同。比如使用 4 个GPU的话，则 4 个进程获得的args.local_rank值分别为0、1、2、3。</p>
</li>
</ol>
<p>上述命令行参数nproc_per_node表示每个节点需要创建多少个进程(使用几个GPU就创建几个)；nnodes表示使用几个节点，做单机多核训练设为1。</p>
<ol>
<li>因为每个进程都会初始化一份模型，为保证模型初始化过程中生成的随机权重相同，需要设置随机种子。方法如下：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def set_seed(seed):</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>使用方式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from torch.utils.data.distributed import DistributedSampler  # 负责分布式dataloader创建，也就是实现上面提到的partition。</span><br><span class="line"></span><br><span class="line"># 负责创建 args.local_rank 变量，并接受 torch.distributed.launch 注入的值</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;--local_rank&quot;, type=int, default=-1)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"># 每个进程根据自己的local_rank设置应该使用的GPU</span><br><span class="line">torch.cuda.set_device(args.local_rank)</span><br><span class="line">device = torch.device(&#x27;cuda&#x27;, args.local_rank)</span><br><span class="line"></span><br><span class="line"># 初始化分布式环境，主要用来帮助进程间通信</span><br><span class="line">torch.distributed.init_process_group(backend=&#x27;nccl&#x27;)</span><br><span class="line"></span><br><span class="line"># 固定随机种子</span><br><span class="line">seed = 42</span><br><span class="line">random.seed(seed)</span><br><span class="line">np.random.seed(seed)</span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line">torch.cuda.manual_seed_all(seed)</span><br><span class="line"></span><br><span class="line"># 初始化模型</span><br><span class="line">model = Net()</span><br><span class="line">model.to(device)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=0.1)</span><br><span class="line"></span><br><span class="line"># 只 master 进程做 logging，否则输出会很乱</span><br><span class="line">if args.local_rank == 0:</span><br><span class="line">    tb_writer = SummaryWriter(comment=&#x27;ddp-training&#x27;)</span><br><span class="line"></span><br><span class="line"># 分布式数据集</span><br><span class="line">train_sampler = DistributedSampler(train_dataset)</span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)  # 注意这里的batch_size是每个GPU上的batch_size</span><br><span class="line"></span><br><span class="line"># 分布式模型</span><br><span class="line">model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True)</span><br></pre></td></tr></table></figure>
<p><strong>torch.distributed.init_process_group</strong>()包含四个常用的参数：</p>
<ul>
<li>backend: 后端, 实际上是多个机器之间交换数据的协议</li>
<li>init_method: 机器之间交换数据, 需要指定一个主节点, 而这个参数就是指定主节点的</li>
<li>world_size: 介绍都是说是进程, 实际就是机器的个数, 例如两台机器一起训练的话, world_size就设置为2</li>
<li>rank: 区分主节点和从节点的, 主节点为0, 剩余的为了1-(N-1), N为要使用的机器的数量, 也就是world_size</li>
</ul>
<h3 id="后端初始化"><a href="#后端初始化" class="headerlink" title="后端初始化"></a>后端初始化</h3><p>pytorch提供下列常用后端：</p>
<p><img src="https://pic2.zhimg.com/80/v2-b4d4a27387dde5cbd043d883948def09_720w.jpg" alt="image"></p>
<h3 id="初始化init-method"><a href="#初始化init-method" class="headerlink" title="初始化init_method"></a>初始化init_method</h3><ol>
<li>TCP初始化</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import torch.distributed as dist</span><br><span class="line"></span><br><span class="line">dist.init_process_group(backend, init_method=&#x27;tcp://10.1.1.20:23456&#x27;,</span><br><span class="line">                        rank=rank, world_size=world_size)</span><br></pre></td></tr></table></figure>
<p>注意这里使用格式为tcp://ip:端口号, 首先ip地址是你的主节点的ip地址, 也就是rank参数为0的那个主机的ip地址, 然后再选择一个空闲的端口号, 这样就可以初始化init_method了.</p>
<ol>
<li>共享文件系统初始化</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import torch.distributed as dist</span><br><span class="line"></span><br><span class="line">dist.init_process_group(backend, init_method=&#x27;file:///mnt/nfs/sharedfile&#x27;,</span><br><span class="line">                        rank=rank, world_size=world_size)</span><br></pre></td></tr></table></figure>
<h3 id="初始化rank和world-size"><a href="#初始化rank和world-size" class="headerlink" title="初始化rank和world_size"></a>初始化rank和world_size</h3><p>这里其实没有多难, 你需要确保, 不同机器的rank值不同, 但是主机的rank必须为0, 而且使用init_method的ip一定是rank为0的主机, 其次world_size是你的主机数量, 你不能随便设置这个数值, 你的参与训练的主机数量达不到world_size的设置值时, 代码是不会执行的.</p>
<h2 id="四、模型保存"><a href="#四、模型保存" class="headerlink" title="四、模型保存"></a>四、模型保存</h2><p>模型的保存与加载，与单GPU的方式有所不同。这里通通将参数以cpu的方式save进存储, 因为如果是保存的GPU上参数，pth文件中会记录参数属于的GPU号，则加载时会加载到相应的GPU上，这样就会导致如果你GPU数目不够时会在加载模型时报错</p>
<p>或者模型保存时控制进程，只在主进程进行保存。<br>模型保存都是一致的，不过分布式运行有多个进程在同时跑，所以会保存多个模型到存储上，如果使用共享存储就要注意文件名的问题，当然一般只在rank0进程上保存参数即可，因为所有进程的模型参数是同步的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.save(model.module.cpu().state_dict(), &quot;model.pth&quot;)</span><br></pre></td></tr></table></figure>
<p>参数加载：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">param=torch.load(&quot;model.pth&quot;)</span><br></pre></td></tr></table></figure>
<p>以下是huggingface/transformers代码中用到的模型保存代码<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if torch.distributed.get_rank() == 0:</span><br><span class="line">    model_to_save = model.module if hasattr(model, &quot;module&quot;) else model  # Take care of distributed/parallel training</span><br><span class="line">    model_to_save.save_pretrained(args.output_dir)</span><br><span class="line">    tokenizer.save_pretrained(args.output_dir)</span><br></pre></td></tr></table></figure></p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://zhuanlan.zhihu.com/p/86441879">pytorch多gpu并行训练</a></p>
<p><a href="https://github.com/jia-zhuang/pytorch-multi-gpu-training">PyTorch 单机多GPU 训练方法与原理整理</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>深度学习</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>Nvidia-Docker配置python3与pytorch环境</title>
    <url>/2021/09/28/2021-09-28-Nvidia-Docker%E9%85%8D%E7%BD%AEpython3%E4%B8%8Epytorch%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p>本文将介绍Nvidia-Docker配置python3与pytorch环境，完成docker容器内安装GPU深度学习环境。<br>TIPS：为了避免下载源过慢，建议添加中科大源/清华源<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak</span><br><span class="line">2. sudo sed -i &#x27;s/archive.ubuntu.com/mirrors.ustc.edu.cn/g&#x27; /etc/apt/sources.list</span><br><span class="line">3. sudo apt update</span><br></pre></td></tr></table></figure></p>
<span id="more"></span>
<h1 id="一、Docker与Nvidia-docker安装"><a href="#一、Docker与Nvidia-docker安装" class="headerlink" title="一、Docker与Nvidia-docker安装"></a>一、Docker与Nvidia-docker安装</h1><h2 id="TIPS：为了避免下载源过慢，建议添加中科大源-清华源"><a href="#TIPS：为了避免下载源过慢，建议添加中科大源-清华源" class="headerlink" title="TIPS：为了避免下载源过慢，建议添加中科大源/清华源"></a>TIPS：为了避免下载源过慢，建议添加中科大源/清华源</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak</span><br><span class="line">2. sudo sed -i &#x27;s/archive.ubuntu.com/mirrors.ustc.edu.cn/g&#x27; /etc/apt/sources.list</span><br><span class="line">3. sudo apt update</span><br></pre></td></tr></table></figure>
<h2 id="1-Docker安装"><a href="#1-Docker安装" class="headerlink" title="1. Docker安装"></a>1. Docker安装</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. Update the apt package index and install packages to allow apt to use a repository over HTTPS:</span><br><span class="line"></span><br><span class="line"> sudo apt-get update</span><br><span class="line"> sudo apt-get install \</span><br><span class="line">    apt-transport-https \</span><br><span class="line">    ca-certificates \</span><br><span class="line">    curl \</span><br><span class="line">    gnupg \</span><br><span class="line">    lsb-release</span><br><span class="line">    </span><br><span class="line">2. Add Docker’s official GPG key:</span><br><span class="line"></span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg</span><br><span class="line"></span><br><span class="line">3. Use the following command to set up the stable repository. To add the nightly or test repository, add the word nightly or test (or both) after the word stable in the commands below. Learn about nightly and test channels.</span><br><span class="line"></span><br><span class="line"> echo \</span><br><span class="line">  &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \</span><br><span class="line">  $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line">  </span><br><span class="line">4. Update the apt package index, and install the latest version of Docker Engine and containerd, or go to the next step to install a specific version:</span><br><span class="line"></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install docker-ce docker-ce-cli containerd.io</span><br><span class="line"></span><br><span class="line">5. To install a specific version of Docker Engine, list the available versions in the repo, then select and install:</span><br><span class="line"></span><br><span class="line">a. List the versions available in your repo:</span><br><span class="line"></span><br><span class="line">apt-cache madison docker-ce</span><br><span class="line"></span><br><span class="line">b. Install a specific version using the version string from the second column, for example, 5:18.09.1~3-0~ubuntu-xenial.</span><br><span class="line"></span><br><span class="line">sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io</span><br><span class="line"></span><br><span class="line">6. Verify that Docker Engine is installed correctly by running the hello-world image.</span><br><span class="line"></span><br><span class="line">sudo docker run hello-world</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="2-Nvidia-Docker-安装"><a href="#2-Nvidia-Docker-安装" class="headerlink" title="2. Nvidia-Docker 安装"></a>2. Nvidia-Docker 安装</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. Setup the stable repository and the GPG key:</span><br><span class="line"></span><br><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \</span><br><span class="line">   &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \</span><br><span class="line">   &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line"></span><br><span class="line">2. To get access to experimental features such as CUDA on WSL or the new MIG capability on A100, you may want to add the experimental branch to the repository listing:</span><br><span class="line"></span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-container-runtime/experimental/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list</span><br><span class="line"></span><br><span class="line">3. Install the nvidia-docker2 package (and dependencies) after updating the package listing:</span><br><span class="line"></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y nvidia-docker2</span><br><span class="line"></span><br><span class="line">4. Restart the Docker daemon to complete the installation after setting the default runtime:</span><br><span class="line"></span><br><span class="line">sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line">5. At this point, a working setup can be tested by running a base CUDA container:</span><br><span class="line">sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi</span><br></pre></td></tr></table></figure>
<h1 id="二、docker内安装python与pytorch环境"><a href="#二、docker内安装python与pytorch环境" class="headerlink" title="二、docker内安装python与pytorch环境"></a>二、docker内安装python与pytorch环境</h1><blockquote>
<p>拉取nvidia包含cuda的基础镜像。拟安装环境：python3.7, pytorch1.6</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 宿主机：提前在宿主机上下载好安装pip3.7要用到的包</span><br><span class="line">curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py</span><br><span class="line"></span><br><span class="line"># 宿主机与容器传输文件</span><br><span class="line">docker cp a.txt containerid:/path</span><br><span class="line"></span><br><span class="line"># 宿主机：运行ubuntu:18.04容器</span><br><span class="line">docker run -it -d --name=lz-ubuntu -v /root/get-pip.py:/root/get-pip.py ubuntu:18.04</span><br><span class="line"></span><br><span class="line"># 宿主机：进入到容器</span><br><span class="line">docker exec -it lz-ubuntu bash</span><br><span class="line"></span><br><span class="line"># 容器内：可选-安装vim</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install vim -y</span><br><span class="line"></span><br><span class="line"># 容器内：配置pip源，用以加速安装</span><br><span class="line">sudo mkdir ~/.pip</span><br><span class="line">sudo vim ~/.pip/pip.conf</span><br><span class="line"></span><br><span class="line">添加以下内容：</span><br><span class="line">[global]</span><br><span class="line">index-url=https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br><span class="line"></span><br><span class="line">国内源：</span><br><span class="line">清华：</span><br><span class="line">https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">阿里云：</span><br><span class="line">http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">中国科技大学 </span><br><span class="line">https://pypi.mirrors.ustc.edu.cn/simple/</span><br><span class="line">华中理工大学：</span><br><span class="line">http://pypi.hustunique.com/</span><br><span class="line">山东理工大学：</span><br><span class="line">http://pypi.sdutlinux.org/</span><br><span class="line">豆瓣：</span><br><span class="line">http://pypi.douban.com/simple/</span><br><span class="line"></span><br><span class="line"># 容器内：可选-配置apt源</span><br><span class="line">mv /etc/apt/sources.list /etc/apt/sources.list.bak</span><br><span class="line">vim /etc/apt/sources.list</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line"></span><br><span class="line"># 容器内：更新软件包列表</span><br><span class="line">apt-get update</span><br><span class="line"></span><br><span class="line"># 容器内：可选-安装调试工具</span><br><span class="line">apt-get install iputils-ping net-tools curl</span><br><span class="line"></span><br><span class="line"># 容器内：安装最主要的python包</span><br><span class="line">apt-get install python3.7 python3.7-dev</span><br><span class="line"></span><br><span class="line"># 容器内：安装pip3.7</span><br><span class="line">apt install python3-distutils</span><br><span class="line">python3.7 get-pip.py</span><br><span class="line"></span><br><span class="line"># 容器内：安装pytorch</span><br><span class="line"># CUDA 10.1</span><br><span class="line">pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html</span><br><span class="line"># 安装其他python包</span><br><span class="line">pip install transformers==2.10.0</span><br><span class="line">pip install pytorch-crf==0.7.2</span><br><span class="line">pip install sklearn</span><br><span class="line">pip install seqeval==1.2.2</span><br><span class="line">pip install pandas</span><br><span class="line"></span><br><span class="line"># 时区设置</span><br><span class="line"># 宿主机：从宿主机中拷贝时区文件到容器内，/usr/share/zoneinfo/UCT这个文件是通过软链追溯到的，时区是亚洲/上海</span><br><span class="line">docker cp /usr/share/zoneinfo/UCT  lyz-ubuntu:/etc/</span><br><span class="line"># 容器内：然后在容器内将其改名为/etc/localtime</span><br><span class="line">mv /etc/UCT /etc/localtime</span><br><span class="line"></span><br><span class="line"># 容器内：清理无用的包</span><br><span class="line">apt-get clean</span><br><span class="line">apt-get autoclean</span><br><span class="line">du -sh /var/cache/apt/</span><br><span class="line">rm -rf /var/cache/apt/archives</span><br><span class="line"></span><br><span class="line"># 容器内：清理pip缓存</span><br><span class="line">rm -rf ~/.cache/pip</span><br><span class="line"></span><br><span class="line"># 容器内：清理命令日志</span><br><span class="line">history -c</span><br><span class="line"></span><br><span class="line"># 宿主机：打包镜像</span><br><span class="line">docker commit -a &#x27;提交人&#x27; -m &#x27;描述&#x27; &lt;容器名/ID&gt; &lt;镜像名称&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="三、nvidia-docker-运行"><a href="#三、nvidia-docker-运行" class="headerlink" title="三、nvidia-docker 运行"></a>三、nvidia-docker 运行</h1><blockquote>
<p>nvidia-docker2版本下nvidia-docker run与docker run —runtime=nvidia效果无太大差异</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># pytorch gpu 可运行</span><br><span class="line">docker run -itd --gpus all --name 容器名 -eNVIDIA_DRIVER_CAPABILITIES=compute,utility -e NVIDIA_VISIBLE_DEVICES=all 镜像名</span><br><span class="line"></span><br><span class="line">多出来的东西其实就是这个家伙：NVIDIA_DRIVER_CAPABILITIES=compute,utility</span><br><span class="line">　　</span><br><span class="line">也就是说，如果你不改这个环境变量，宿主机的nvidia driver在容器内是仅作为utility存在的，如果加上compute，宿主机的英伟达driver将对容器提供计算支持（所谓的计算支持也就是cuda支持）。</span><br><span class="line"></span><br><span class="line"># nvidia-docker2验证</span><br><span class="line">nvidia-docker --version</span><br><span class="line"></span><br><span class="line"># nvidia-docker2 测试</span><br><span class="line">docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi</span><br><span class="line"></span><br><span class="line"># nvidia-docker2启动</span><br><span class="line">启动nvidia-docker：</span><br><span class="line">      $: systemctl start nvidia-docker</span><br><span class="line"> 查看docker服务是否启动：</span><br><span class="line">      $: systemctl status nvidia-docker</span><br></pre></td></tr></table></figure>
<h2 id="1-docker-run-参数介绍"><a href="#1-docker-run-参数介绍" class="headerlink" title="1. docker run 参数介绍"></a>1. docker run 参数介绍</h2><p><strong>docker run 常用参数介绍：</strong></p>
<ul>
<li><p>—rm选项，这样在容器退出时就能够自动清理容器内部的文件系统。</p>
</li>
<li><p>—i选项，打开STDIN，用于控制台交互</p>
</li>
<li><p>—t选项，分配tty设备，该可以支持终端登录，默认为false</p>
</li>
<li><p>—d选项，指定容器运行于前台还是后台，默认为false</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">其他参数介绍：</span><br><span class="line">  -u, --user=&quot;&quot;              指定容器的用户  </span><br><span class="line">  -a, --attach=[]            登录容器（必须是以docker run -d启动的容器）</span><br><span class="line">  -w, --workdir=&quot;&quot;           指定容器的工作目录 </span><br><span class="line">  -c, --cpu-shares=0        设置容器CPU权重，在CPU共享场景使用  </span><br><span class="line">  -e, --env=[]               指定环境变量，容器中可以使用该环境变量  </span><br><span class="line">  -m, --memory=&quot;&quot;            指定容器的内存上限  </span><br><span class="line">  -P, --publish-all=false    指定容器暴露的端口  </span><br><span class="line">  -p, --publish=[]           指定容器暴露的端口 </span><br><span class="line">  -h, --hostname=&quot;&quot;          指定容器的主机名  </span><br><span class="line">  -v, --volume=[]            给容器挂载存储卷，挂载到容器的某个目录  </span><br><span class="line">  --volumes-from=[]          给容器挂载其他容器上的卷，挂载到容器的某个目录</span><br><span class="line">  --cap-add=[]               添加权限，权限清单详见：http://linux.die.net/man/7/capabilities  </span><br><span class="line">  --cap-drop=[]              删除权限，权限清单详见：http://linux.die.net/man/7/capabilities  </span><br><span class="line">  --cidfile=&quot;&quot;               运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法  </span><br><span class="line">  --cpuset=&quot;&quot;                设置容器可以使用哪些CPU，此参数可以用来容器独占CPU  </span><br><span class="line">  --device=[]                添加主机设备给容器，相当于设备直通  </span><br><span class="line">  --dns=[]                   指定容器的dns服务器  </span><br><span class="line">  --dns-search=[]            指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件  </span><br><span class="line">  --entrypoint=&quot;&quot;            覆盖image的入口点  </span><br><span class="line">  --env-file=[]              指定环境变量文件，文件格式为每行一个环境变量  </span><br><span class="line">  --expose=[]                指定容器暴露的端口，即修改镜像的暴露端口  </span><br><span class="line">  --link=[]                  指定容器间的关联，使用其他容器的IP、env等信息  </span><br><span class="line">  --lxc-conf=[]              指定容器的配置文件，只有在指定--exec-driver=lxc时使用  </span><br><span class="line">  --name=&quot;&quot;                  指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字  </span><br><span class="line">  --net=&quot;bridge&quot;             容器网络设置:</span><br><span class="line">				                bridge 使用docker daemon指定的网桥     </span><br><span class="line">				                host 	//容器使用主机的网络  </span><br><span class="line">				                container:NAME_or_ID  &gt;//使用其他容器的网路，共享IP和PORT等网络资源  </span><br><span class="line">				                none 容器使用自己的网络（类似--net=bridge），但是不进行配置 </span><br><span class="line">  --privileged=false         指定容器是否为特权容器，特权容器拥有所有的capabilities  </span><br><span class="line">  --restart=&quot;no&quot;             指定容器停止后的重启策略:</span><br><span class="line">				                no：容器退出时不重启  </span><br><span class="line">				                on-failure：容器故障退出（返回值非零）时重启 </span><br><span class="line">				                always：容器退出时总是重启  </span><br><span class="line">  --rm=false                 指定容器停止后自动删除容器(不支持以docker run -d启动的容器)  </span><br><span class="line">  --sig-proxy=true           设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理  </span><br><span class="line">  </span><br></pre></td></tr></table></figure>
<h2 id="2-docker-常用命令"><a href="#2-docker-常用命令" class="headerlink" title="2. docker 常用命令"></a>2. docker 常用命令</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> ### 显示版本信息 (与python, nvcc相比少了两个‘--’）</span><br><span class="line">$ docker version</span><br><span class="line"></span><br><span class="line">### 了解当前Docker的使用状态（当前容器，镜像数目信息，存储空间占用信息，</span><br><span class="line"># OS内核版本， 发行版本， 硬件资源等）</span><br><span class="line">$ docker info</span><br><span class="line"></span><br><span class="line">### 拉去一个镜像 ( xxxx 表示某个镜像名字，）</span><br><span class="line">$ docker pull xxxx</span><br><span class="line"># e.g.</span><br><span class="line"># docker pull ubuntu</span><br><span class="line"></span><br><span class="line">### 查看系统中已有的镜像(images要带‘s&#x27;)</span><br><span class="line">$ docker images</span><br><span class="line"># e.g.:</span><br><span class="line"># REPOSITORY  TAG    IMAGES ID   CREATED VIRTUAL SIZE</span><br><span class="line"># ubuntu      latest 4ef6axxxxx   5 day ago  84.0M</span><br><span class="line"></span><br><span class="line">### 从镜像创建docker容器</span><br><span class="line">$ docker run -i -t ubuntu /bin/bash </span><br><span class="line"># or</span><br><span class="line">$ docker run -it 4ef /bin/bash</span><br><span class="line"># 其中 -i, 交互模式，让输入输出都在标准控制台进行；-d，则进入后台</span><br><span class="line"># -t, 为新创建的容器分配一个伪终端</span><br><span class="line"># ubuntu, 用于创建容器的镜像名，可用ID来代替（前3位足够）</span><br><span class="line"># /bin/bash， 在新建容器中运行的命令，可以为任意Linux命令</span><br><span class="line"></span><br><span class="line">### 离开当前容器,返回宿主机终端，使用组合键 &quot;Ctrl+P&quot; 和 &quot;Ctrl+Q&quot;</span><br><span class="line"></span><br><span class="line">### 查看当前活动的容器</span><br><span class="line">$ docker ps</span><br><span class="line"># CONTAINER ID  IMAGE  COMMAND  CREATED   STATUS   PORTS NAME</span><br><span class="line"># 610xxxx  ubuntu:latest  &quot;/bin/bash&quot; 1 minute ago Up 1 minute ago prickly_wilson</span><br><span class="line"></span><br><span class="line">### 宿主机终端与某个容器建立连接</span><br><span class="line">$ docker attach 610</span><br><span class="line"></span><br><span class="line">### 从容器创建Docker镜像</span><br><span class="line">$ docker commit -m &quot;hhahaha&quot; 610 ubuntu:hhh</span><br><span class="line"># -m, 新镜像说明</span><br><span class="line"># 610， 某个容器的ID</span><br><span class="line"># ubuntu:hhh， 命名最好不要这么随意</span><br><span class="line"># 那么接下来可以查看新生成的镜像，命令 docker images</span><br><span class="line"></span><br><span class="line">### 基于新的镜像创建一个新的容器(一样的)</span><br><span class="line">$ docker run -it ubuntu:hhh /bin/bash</span><br><span class="line"></span><br><span class="line">### 给镜像重命名(方便记忆)</span><br><span class="line">$ docker tag IMAGEID(image id) REPOSITORY:TAG</span><br><span class="line"></span><br><span class="line">### 给容器重命名</span><br><span class="line">$ docker rename old-container-name new-container-name</span><br></pre></td></tr></table></figure>
<h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p><a href="https://blog.csdn.net/qq_39698985/article/details/109524762">https://blog.csdn.net/qq_39698985/article/details/109524762</a></p>
<p><a href="https://blog.csdn.net/mumoDM/article/details/82503022">https://blog.csdn.net/mumoDM/article/details/82503022</a></p>
<p><a href="https://blog.csdn.net/qq_29518275/article/details/107486028">https://blog.csdn.net/qq_29518275/article/details/107486028</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>深度学习</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>GPU</tag>
        <tag>Nvidia-Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention可视化</title>
    <url>/2021/12/24/2021-12-24-Attention%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<p>本文介绍了Attention可视化的方式，包含两种热力图可视化、文本可视化。</p>
<ol>
<li>使用matplotlib与seaborn完成attention矩阵的热力图绘制</li>
<li>根据注意力矩阵，得到html颜色深浅代表相关性强弱</li>
</ol>
<span id="more"></span>
<h1 id="热力图可视化"><a href="#热力图可视化" class="headerlink" title="热力图可视化"></a>热力图可视化</h1><blockquote>
<p>使用matplotlib与seaborn完成attention矩阵的热力图绘制</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line"># author:   LZ</span><br><span class="line"># create time:  2021/11/15 14:54</span><br><span class="line"># file: genpic.py</span><br><span class="line"># IDE:  PyCharm</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.ticker as ticker</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">gperes = &#123;</span><br><span class="line">     &#x27;武&#x27;: &#123;&#x27;武&#x27;: 0.1, &#x27;汉&#x27;: 0.9, &#x27;市&#x27;: 1, &#x27;长&#x27;: 0.05, &#x27;江&#x27;: 0.09, &#x27;大&#x27;: 0.03, &#x27;桥&#x27;: 0.2&#125;,</span><br><span class="line">     &#x27;汉&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0.2, &#x27;市&#x27;: 0.1, &#x27;长&#x27;: 0.03, &#x27;江&#x27;: 0.04, &#x27;大&#x27;: 0.02, &#x27;桥&#x27;: 0.07&#125;,</span><br><span class="line">     &#x27;市&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0.1, &#x27;长&#x27;: 0.01, &#x27;江&#x27;: 0.02, &#x27;大&#x27;: 0.03, &#x27;桥&#x27;: 0.05&#125;,</span><br><span class="line">     &#x27;长&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0, &#x27;长&#x27;: 0.25, &#x27;江&#x27;: 0.1, &#x27;大&#x27;: 0.08, &#x27;桥&#x27;: 0.09&#125;,</span><br><span class="line">     &#x27;江&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0, &#x27;长&#x27;: 0, &#x27;江&#x27;: 0.15, &#x27;大&#x27;: 0.04, &#x27;桥&#x27;: 0.015&#125;,</span><br><span class="line">     &#x27;大&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0, &#x27;长&#x27;: 0, &#x27;江&#x27;: 0, &#x27;大&#x27;: 0.14, &#x27;桥&#x27;: 0.15&#125;,</span><br><span class="line">     &#x27;桥&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0, &#x27;长&#x27;: 0, &#x27;江&#x27;: 0, &#x27;大&#x27;: 0, &#x27;桥&#x27;: 0.12&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">newgperes = &#123;&#125;</span><br><span class="line">for k, v in gperes.items():</span><br><span class="line">     for w, a in v.items():</span><br><span class="line">          newgperes.setdefault(w, &#123;&#125;)</span><br><span class="line">          newgperes[w][k] = a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.rcParams[&#x27;font.sans-serif&#x27;]=[&#x27;Arial Unicode MS&#x27;]</span><br><span class="line">plt.rcParams[&#x27;axes.unicode_minus&#x27;] = False</span><br><span class="line">gpedata = pd.DataFrame(newgperes)</span><br><span class="line">ax = sns.heatmap(gpedata, cmap=&quot;YlOrRd&quot;)</span><br><span class="line">ax.xaxis.tick_top()</span><br><span class="line">ax.set_yticklabels(ax.get_yticklabels(), rotation=0)</span><br><span class="line">plt.savefig(&#x27;loctest.png&#x27;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://s3.bmp.ovh/imgs/2021/12/4100fe169b8b9921.png" alt="gpe.png"></p>
<h1 id="NLP文本注意力可视化"><a href="#NLP文本注意力可视化" class="headerlink" title="NLP文本注意力可视化"></a>NLP文本注意力可视化</h1><blockquote>
<p>根据注意力矩阵，得到html颜色深浅代表相关性强弱</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Credits to Lin Zhouhan(@hantek) for the complete visualization code</span><br><span class="line">import random, os, numpy, scipy</span><br><span class="line">from codecs import open</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def createHTML(texts, weights, savepath):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Creates a html file with text heat.</span><br><span class="line">	weights: attention weights for visualizing</span><br><span class="line">	texts: text on which attention weights are to be visualized</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    fOut = open(savepath, &quot;w&quot;, encoding=&quot;utf-8&quot;)</span><br><span class="line">    part1 = &quot;&quot;&quot;</span><br><span class="line">    &lt;html lang=&quot;en&quot;&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;</span><br><span class="line">    &lt;style&gt;</span><br><span class="line">    body &#123;</span><br><span class="line">    font-family: Sans-Serif;</span><br><span class="line">    &#125;</span><br><span class="line">    &lt;/style&gt;</span><br><span class="line">    &lt;/head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">    &lt;h3&gt;</span><br><span class="line">    Heatmaps</span><br><span class="line">    &lt;/h3&gt;</span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">    &lt;script&gt;</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    part2 = &quot;&quot;&quot;</span><br><span class="line">    var color = &quot;255,0,0&quot;;</span><br><span class="line">    var ngram_length = 3;</span><br><span class="line">    var half_ngram = 1;</span><br><span class="line">    for (var k=0; k &lt; any_text.length; k++) &#123;</span><br><span class="line">    var tokens = any_text[k].split(&quot; &quot;);</span><br><span class="line">    var intensity = new Array(tokens.length);</span><br><span class="line">    var max_intensity = Number.MIN_SAFE_INTEGER;</span><br><span class="line">    var min_intensity = Number.MAX_SAFE_INTEGER;</span><br><span class="line">    for (var i = 0; i &lt; intensity.length; i++) &#123;</span><br><span class="line">    intensity[i] = 0.0;</span><br><span class="line">    for (var j = -half_ngram; j &lt; ngram_length-half_ngram; j++) &#123;</span><br><span class="line">    if (i+j &lt; intensity.length &amp;&amp; i+j &gt; -1) &#123;</span><br><span class="line">    intensity[i] += trigram_weights[k][i + j];</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if (i == 0 || i == intensity.length-1) &#123;</span><br><span class="line">    intensity[i] /= 2.0;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">    intensity[i] /= 3.0;</span><br><span class="line">    &#125;</span><br><span class="line">    if (intensity[i] &gt; max_intensity) &#123;</span><br><span class="line">    max_intensity = intensity[i];</span><br><span class="line">    &#125;</span><br><span class="line">    if (intensity[i] &lt; min_intensity) &#123;</span><br><span class="line">    min_intensity = intensity[i];</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    var denominator = max_intensity - min_intensity;</span><br><span class="line">    for (var i = 0; i &lt; intensity.length; i++) &#123;</span><br><span class="line">    intensity[i] = (intensity[i] - min_intensity) / denominator;</span><br><span class="line">    &#125;</span><br><span class="line">    if (k%2 == 0) &#123;</span><br><span class="line">    var heat_text = &quot;&lt;p&gt;&lt;br&gt;&lt;b&gt;Example:&lt;/b&gt;&lt;br&gt;&quot;;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">    var heat_text = &quot;&lt;b&gt;Example:&lt;/b&gt;&lt;br&gt;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">    var space = &quot;&quot;;</span><br><span class="line">    for (var i = 0; i &lt; tokens.length; i++) &#123;</span><br><span class="line">    heat_text += &quot;&lt;span style=&#x27;background-color:rgba(&quot; + color + &quot;,&quot; + intensity[i] + &quot;)&#x27;&gt;&quot; + space + tokens[i] + &quot;&lt;/span&gt;&quot;;</span><br><span class="line">    if (space == &quot;&quot;) &#123;</span><br><span class="line">    space = &quot; &quot;;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    //heat_text += &quot;&lt;p&gt;&quot;;</span><br><span class="line">    document.body.innerHTML += heat_text;</span><br><span class="line">    &#125;</span><br><span class="line">    &lt;/script&gt;</span><br><span class="line">    &lt;/html&gt;&quot;&quot;&quot;</span><br><span class="line">    putQuote = lambda x: &quot;\&quot;%s\&quot;&quot; % x</span><br><span class="line">    textsString = &quot;var any_text = [%s];\n&quot; % (&quot;,&quot;.join(map(putQuote, texts)))</span><br><span class="line">    weightsString = &quot;var trigram_weights = [%s];\n&quot; % (&quot;,&quot;.join(map(str, weights)))</span><br><span class="line">    fOut.write(part1)</span><br><span class="line">    fOut.write(textsString)</span><br><span class="line">    fOut.write(weightsString)</span><br><span class="line">    fOut.write(part2)</span><br><span class="line">    fOut.close()</span><br><span class="line"></span><br><span class="line">    return</span><br><span class="line"></span><br><span class="line">gperes = &#123;</span><br><span class="line">     &#x27;武&#x27;: &#123;&#x27;武&#x27;: 0.1, &#x27;汉&#x27;: 0.9, &#x27;市&#x27;: 1, &#x27;长&#x27;: 0.05, &#x27;江&#x27;: 0.09, &#x27;大&#x27;: 0.03, &#x27;桥&#x27;: 0.2&#125;,</span><br><span class="line">     &#x27;汉&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0.2, &#x27;市&#x27;: 0.1, &#x27;长&#x27;: 0.03, &#x27;江&#x27;: 0.04, &#x27;大&#x27;: 0.02, &#x27;桥&#x27;: 0.07&#125;,</span><br><span class="line">     &#x27;市&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0.1, &#x27;长&#x27;: 0.01, &#x27;江&#x27;: 0.02, &#x27;大&#x27;: 0.03, &#x27;桥&#x27;: 0.05&#125;,</span><br><span class="line">     &#x27;长&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0, &#x27;长&#x27;: 0.25, &#x27;江&#x27;: 0.1, &#x27;大&#x27;: 0.08, &#x27;桥&#x27;: 0.09&#125;,</span><br><span class="line">     &#x27;江&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0, &#x27;长&#x27;: 0, &#x27;江&#x27;: 0.15, &#x27;大&#x27;: 0.04, &#x27;桥&#x27;: 0.015&#125;,</span><br><span class="line">     &#x27;大&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0, &#x27;长&#x27;: 0, &#x27;江&#x27;: 0, &#x27;大&#x27;: 0.14, &#x27;桥&#x27;: 0.15&#125;,</span><br><span class="line">     &#x27;桥&#x27;: &#123;&#x27;武&#x27;: 0, &#x27;汉&#x27;: 0, &#x27;市&#x27;: 0, &#x27;长&#x27;: 0, &#x27;江&#x27;: 0, &#x27;大&#x27;: 0, &#x27;桥&#x27;: 0.12&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">matrix = []</span><br><span class="line"># 获取矩阵表示</span><br><span class="line">for k, v in gperes.items():</span><br><span class="line">    matrix.append(list(v.values()))</span><br><span class="line">str_ = &#x27;武 汉 市 长 江 大 桥&#x27;</span><br><span class="line">createHTML([str_] * 7,</span><br><span class="line">           matrix,</span><br><span class="line">           &#x27;./visualization/test.html&#x27;)</span><br></pre></td></tr></table></figure>
<p><img src="https://i.bmp.ovh/imgs/2021/12/04573a3a1f1fb2b6.png" alt="wx20211211-193035@2x.png"></p>
<h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p><a href="https://blog.csdn.net/qq_38607066/article/details/101345282#t17">https://blog.csdn.net/qq_38607066/article/details/101345282#t17</a></p>
<p><a href="https://blog.csdn.net/u010490755/article/details/89574847">https://blog.csdn.net/u010490755/article/details/89574847</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>NLP</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Attention</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习基础-神经网络权重初始化</title>
    <url>/2021/09/29/2021-09-29-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
    <content><![CDATA[<p>本文将介绍神经网络权重初始化的原理与实现。首先解决了两个问题：1. 全零初始化是否可以、2. 参数全部相同初始化是否可以</p>
<p>然后介绍了初始化的方式：</p>
<ol>
<li>预训练初始化</li>
<li>随机初始化</li>
<li>固定初始化</li>
</ol>
<span id="more"></span>
<h1 id="一、两个问题"><a href="#一、两个问题" class="headerlink" title="一、两个问题"></a>一、两个问题</h1><blockquote>
<p>假设3层神经网络,输入节点v0，第一层节点v1,v2,v3 第二层节点v4,v5 第三层节点v6。其中vi=f(ai),i=4,5,6 f为激活函数。</p>
</blockquote>
<p><strong>前向传播：</strong></p>
<p><img src="https://img-blog.csdnimg.cn/83cc1293388e439ab8a1d33e6c67396f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASk1YR09ETFo=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h2 id="1-全零初始化是否可以"><a href="#1-全零初始化是否可以" class="headerlink" title="1. 全零初始化是否可以"></a>1. 全零初始化是否可以</h2><p>一般情况不可以。当全零参数初始化时，除输入节点所有节点值均为0,根据上式除第一层梯度与输入值有关其余均为0.</p>
<p>LR等一层网络可以全零初始化， 网络梯度与输入值有关。仅全零初始化一层也不影响训练，但涉及两层及以上，从涉及层到输入层的梯度都为0,参数无法更新。</p>
<h2 id="2-参数全部相同初始化是否可以"><a href="#2-参数全部相同初始化是否可以" class="headerlink" title="2. 参数全部相同初始化是否可以"></a>2. 参数全部相同初始化是否可以</h2><p>不可以。若初始化为相同的参数，隐藏层所有节点输出相同，梯度也是相同的。相当于输入经过一个节点。</p>
<h1 id="二、参数初始化方式"><a href="#二、参数初始化方式" class="headerlink" title="二、参数初始化方式"></a>二、参数初始化方式</h1><h2 id="1-预训练初始化"><a href="#1-预训练初始化" class="headerlink" title="1. 预训练初始化"></a>1. 预训练初始化</h2><p><strong>pretraining + finetuning</strong>加载已训练好的模型参数，进行下游任务的模型训练。</p>
<h2 id="2-随机初始化"><a href="#2-随机初始化" class="headerlink" title="2. 随机初始化"></a>2. 随机初始化</h2><h3 id="2-1-random-initialization"><a href="#2-1-random-initialization" class="headerlink" title="2.1 random initialization"></a>2.1 random initialization</h3><p><code>random initialization: np.random.randn(m,n)</code></p>
<p>随机产生符合正态分布的m×n维向量</p>
<p>弊端：随机会产生梯度消失，随着网络层次加深，由于链式求导法则，输出越来越接近0</p>
<h3 id="2-2-Xavier-initialization"><a href="#2-2-Xavier-initialization" class="headerlink" title="2.2 Xavier initialization"></a>2.2 Xavier initialization</h3><p><code>tf.Variable(np.random.randn(node_in,node_out))/np.sqrt(node_in)</code></p>
<p><img src="https://pic3.zhimg.com/80/v2-6302a7093b93e1376e54e95033c58086_720w.jpg" alt="image"></p>
<p>M 代表着输入输出维度即node_in,node_out</p>
<p>保证输入输出方差一致</p>
<h3 id="2-3-He-initialization"><a href="#2-3-He-initialization" class="headerlink" title="2.3 He initialization"></a>2.3 He initialization</h3><p><code>tf.Variable(np.random.randn(node_in,node_out))/np.sqrt(node_in/2)</code></p>
<p>适用于RELU激活函数，只有半区有效</p>
<h2 id="3-固定初始化"><a href="#3-固定初始化" class="headerlink" title="3. 固定初始化"></a>3. 固定初始化</h2><p>比如对于偏置（bias）通常用0初始化，LSTM遗忘门偏置通常为1或2，使时序上的梯度变大，对于ReLU神经元，偏置设为0.01，使得训练初期更容易激活。</p>
<h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p><a href="https://note.youdao.com/">https://www.leiphone.com/category/ai/3qMp45aQtbxTdzmK.html</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>深度学习</category>
        <category>基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>权重初始化</tag>
      </tags>
  </entry>
  <entry>
    <title>2022预训练的下一步是什么</title>
    <url>/2021/12/31/2021-12-31-2022%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E4%B8%8B%E4%B8%80%E6%AD%A5%E6%98%AF%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文内容为自己对2021年自身算法经历的回顾，同时展望了未来研究的方向。如有理解不对的地方，欢迎指正批评。</p>
<p>2021年研究热点</p>
<ul>
<li>大规模预训练</li>
<li>对比学习</li>
<li>prompt</li>
</ul>
<p>展望未来</p>
<p>回顾自身算法经历</p>
<ol>
<li>需求分析</li>
<li>模型选型及设计</li>
<li>数据分析</li>
<li>模型训练及优化</li>
<li>分析负例<ol>
<li>检查数据质量是否过差</li>
<li>根据指标进行分析<ul>
<li>recall低</li>
<li>precision低</li>
</ul>
</li>
</ol>
</li>
</ol>
<span id="more"></span>
<blockquote>
<p>该内容为自己对2021年自身算法经历的回顾，同时展望了未来研究的方向。如有理解不对的地方，欢迎指针批评。</p>
</blockquote>
<h1 id="2021年研究热点"><a href="#2021年研究热点" class="headerlink" title="2021年研究热点"></a>2021年研究热点</h1><h2 id="大规模预训练"><a href="#大规模预训练" class="headerlink" title="大规模预训练"></a>大规模预训练</h2><p>预训练+微调的做法，在多个下游领域取得优异的表现。而在过去的一年里，预训练模型更是在往<strong>大而深</strong>的方向发展。</p>
<p>目前，国内已有智源研究院、鹏城实验室、中科院自动化所、阿里、百度、华为、浪潮等科研院所和企业研相继发出“悟道”、“盘古”、“紫东 · 太初”、M6、PLUG、ERNIE 3.0 等大模型。</p>
<p>但是模型在往大而深方向发展的同时，也存在如下亟待解决的问题：</p>
<ul>
<li>如何解释预训练模型的理论基础（如大模型智能的参数规模极限存在吗）</li>
<li>如何将大模型高效、低成本的应用于实际系统</li>
<li>如何克服构建大模型的数据质量、训练效率、算力消耗、模型交付等诸多障碍</li>
<li>如何解决目前大部分大模型普遍缺乏认知能力的问题</li>
</ul>
<h2 id="对比学习"><a href="#对比学习" class="headerlink" title="对比学习"></a>对比学习</h2><p><strong>对比学习的出发点在于避免模型坍塌，理想的模型应该符合alignment和uniformity，即语义相近的句子彼此聚集，语义无关的句子均匀分布。</strong></p>
<p>如果仅仅通过数据增强构建正例，随机句子作为负例，并为其打上0，1标签，存在以下问题：</p>
<ul>
<li>数据增强生成正例的变化有限</li>
<li>随机搭配成负例，含有除正例组合外其他组合全部为0的诱导</li>
<li>0，1标签的赋予太过绝对，对相似性表述不够准确</li>
</ul>
<p>因此对比学习的核心思想转变为：</p>
<script type="math/tex; mode=display">score(X,X^{'}) >> score(X,Y)</script><p>其中，X代表原样本，$X^{‘}$代表数据增强的正样本，Y代表随机选择的负样本。</p>
<p>根据该思想，对比学习采用InfoNCE损失函数：</p>
<script type="math/tex; mode=display">loss = -log \frac{exp(score(X,X^{'}))}{score(X,X^{'})+\sum_{i=1}^{N}score(X,Y_i)}</script><p>通过该损失函数实现正例拉近，负例推远的效果。</p>
<h2 id="prompt"><a href="#prompt" class="headerlink" title="prompt"></a>prompt</h2><p>prompt被誉为NLP领域的新范式，与预训练+微调的范式相比，其过程分为：”pre-train, prompt, and predict”。</p>
<p><strong>prompt的出发点在于以更轻量化的方式利用预训练模型，避免微调与预训练之间存在的差异。</strong></p>
<p>prompt通过构建模版的方式，将下游任务转为与预训练相似的MLM任务，以该方式充分发挥预训练模型的性能。</p>
<p>以文本情感分类任务中，”I love this movie.”句子为例，prompt按照以下方式进行处理：</p>
<ol>
<li>生成prompt句子</li>
</ol>
<p>该步骤完成输入句子到模型输入的映射：</p>
<script type="math/tex; mode=display">x^{'}=f_{prompt}(x)</script><p>其中，$x^{‘}$为生成的prompt句子，x为输入句子，$f_{prompt}$为prompt函数。</p>
<p>在本例中，使用的模版为： “ [X] Overall, it was a [Z] movie.”</p>
<p>因此，得到的，$x^{‘}$为”I love this movie. Overall it was a [Z] movie.”</p>
<ol>
<li>模型预测</li>
</ol>
<p>该步骤将$x^{‘}$输入模型，模型完成模版空白位置的词语预测。</p>
<p>在本例中，模型可能预测为：”excellent”, “great”, “wonderful” 等词语</p>
<ol>
<li>结果映射</li>
</ol>
<p>通常模型预测的词语与任务输出存在一定差距，因此我们需要完成词语到输出结果的映射。</p>
<script type="math/tex; mode=display">y = f(x^{'})</script><p>在本例中，”excellent”, “great”, “wonderful” 等词语映射为标签 “++”</p>
<h1 id="展望未来"><a href="#展望未来" class="headerlink" title="展望未来"></a>展望未来</h1><p>首先我认为当前基于数据驱动方法存在如下的问题：</p>
<ol>
<li>长尾效应：自然界中的数据分布就是长尾的，在学习的过程中，模型容易发生过拟合，泛化性较差。</li>
<li>数据噪声：有标签的数据，在标注过程中就不可避免的存在噪声。尤其是多位人员一起标注时，不同标注人员根据自身的理解完成数据的标注，但不同的人自身理解存在偏差，因此标注结果极易存在误差。归根到底：标注的规范难以确定，无法统一大家的知识库。</li>
</ol>
<p>当前我遇到的一些问题分享：模型仍无法很好地处理下述问题：</p>
<blockquote>
<p>太阳有几只眼睛？</p>
<p>姚明与奥尼尔身高谁比较高？</p>
<p>猫咪可以吃生蛋黄吗？猫咪是可以吃蛋黄的。这里特定煮熟的白水蛋，猫咪不能吃生鸡蛋，因为生鸡蛋中有细菌。</p>
<p>物质都是由分子构成的吗？物质都是由分子构成的，分子又由原子构成-错的！因为有些物质是不含分子的。</p>
</blockquote>
<p>这些问题，我总结为两方面的困难：</p>
<ol>
<li>缺乏知识，由于预训练与微调领域存在偏差，模型在下游任务中缺乏特定知识，同时模型在一些常识问题上表现较差。</li>
<li>缺乏深度语义的理解，模型表现的更像通过字面匹配完成任务，推理的成分更弱。</li>
</ol>
<p>当前研究热点仍然在于挖掘预训练模型的能力，但在基于常识性知识与逻辑推理的问题上，这种基于数据驱动的方式从底层就存在问题。引用一下大咖们对2022年的展望。</p>
<blockquote>
<p>大模型一方面在不少问题上取得了以往难以预期的成功，另一方面其巨大的训练能耗和碳排放是不能忽视的问题。个人以为，大模型未来会在一些事关国计民生的重大任务上发挥作用，而在其他一些场景下或许会通过类似集成学习的手段来利用小模型，尤其是通过很少量训练来 “复用” 和集成已有的小模型来达到不错的性能。</p>
<p>我们提出了一个叫做 “学件” 的思路，目前在做一些这方面的探索。大致思想是，假设很多人已经做了模型并且乐意放到某个市场去共享，市场通过建立规约来组织和管理学件，以后的人再做新应用时，就可以不用从头收集数据训练模型，可以先利用规约去市场里找找看是否有比较接近需求的模型，然后拿回家用自己的数据稍微打磨就能用。这其中还有一些技术挑战需要解决，我们正在研究这个方向。</p>
<p>另一方面，有可能通过利用人类的常识和专业领域知识，使模型得以精简，这就要结合逻辑推理和机器学习。逻辑推理比较善于利用人类知识，机器学习比较善于利用数据事实，如何对两者进行有机结合一直是人工智能中的重大挑战问题。麻烦的是逻辑推理是严密的基于数理逻辑的 “从一般到特殊”的演绎过程，机器学习是不那么严密的概率近似正确的 “从特殊到一般”的归纳过程，在方法论上就非常不一样。已经有的探索大体上是以其中某一方为倚重，引入另一方的某些成分，我们最近在探索双方相对均衡互促利用的方式。</p>
</blockquote>
<p>谈谈自己的理解，<strong>预训练模型的方式归根到底仍然属于数据驱动的任务，其通过在大规模数据上学习，推断未知数据的概率。如果说数据中存在表述不准确、表述有歧义或者词汇本身就有多个含义的话，以概率的方式难以解决这些问题。</strong> 而人脑在未知问题上，推理成分居多，以一词多义为例，人类会考虑该词汇有几种用法，考虑在这种上下文语境下使用哪一种用法，所以是否可以建立一套类似于标准公理的语言规范，以该规范为基础，对未知句子进行拆解推理，理解句子的完整含义。通过了解模型的推理过程，模型的可解释性增强。当预测错误时，我们可以进行溯源分析，对模型依赖的知识进行调整，或者让模型学习的更充分。</p>
<p>接下来对自己2022年的期望：</p>
<ol>
<li>自身学习更多模型结构变化的同时，更多地理解业务的架构，明白模型在业务中起的作用。</li>
<li>在算法研究上能够研究的更加深入，希望能够找到解决上述困难的方法。</li>
</ol>
<h1 id="回顾自身算法经历"><a href="#回顾自身算法经历" class="headerlink" title="回顾自身算法经历"></a>回顾自身算法经历</h1><p>2021年自身的算法经历主要分为：实习、算法比赛、项目、论文四部分。在这些经历里面主要接触分类、阅读理解、信息抽取三种任务，评估方式均采用精确率、召回率及F1值。下面将以这些经历为基础，介绍我处理这些任务的方式。</p>
<h2 id="1-需求分析"><a href="#1-需求分析" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h2><p>开展算法工作之前，首先要搞清楚算法需要满足什么样的需求。包括：</p>
<ul>
<li>业务属于什么样的任务</li>
<li>算法需要侧重的方向</li>
<li>训练数据及线上数据的情况</li>
<li>线上的指标</li>
<li>线下的评估方式</li>
<li>……</li>
</ul>
<p><strong>需求分析的目的在于了解业务的需求与算法在业务中起到的作用。</strong></p>
<h2 id="2-模型选型及设计"><a href="#2-模型选型及设计" class="headerlink" title="2. 模型选型及设计"></a>2. 模型选型及设计</h2><p>在明白需求之后，需要根据任务类型选择模型，并根据需求的不同，对模型结构进行调整。如阅读理解任务下：针对多答案、无答案的情况，我们需要调整模型的结构。</p>
<p><strong>模型选型及设计的目的在于选择或设计能够很好地满足业务需求的模型。</strong></p>
<h2 id="3-数据分析"><a href="#3-数据分析" class="headerlink" title="3. 数据分析"></a>3. 数据分析</h2><p><strong>数据分析这一步是最重要的一步，当前模型主要还是以数据驱动，数据对模型的影响很大。</strong> </p>
<p>我主要从以下角度进行分析：</p>
<ul>
<li>数据是否存在噪声：标点、大小写、特殊符号等</li>
<li>训练集测试集分布是否存在差异，测试集能否反映模型在具体业务下的表现</li>
<li>数据存在哪些特征，通过引入额外的特征，模型可以表现地更好</li>
<li>训练集分布：标签分布、长度分布等，是否会给模型带来类别不均衡、长文本等问题</li>
<li>数据量大小，数据量足够时可以继续预训练</li>
</ul>
<p><strong>数据分析的目的在于数据能否充分发挥模型性能，能否得到符合业务需求的模型</strong></p>
<h2 id="4-模型训练及优化"><a href="#4-模型训练及优化" class="headerlink" title="4. 模型训练及优化"></a>4. 模型训练及优化</h2><p><strong>模型进行训练，开始炼丹【调参】。</strong></p>
<ul>
<li>设置合适的超参数【可以通过一些超参数搜索算法】</li>
<li>选择合适的优化器【adam/adamw/sgd】</li>
<li>学习率调整的策略</li>
</ul>
<p><strong>进阶版：</strong></p>
<ul>
<li>对抗训练</li>
<li>对比学习</li>
<li>UDA等数据增强方式</li>
<li>继续预训练</li>
<li>多任务学习</li>
<li>伪标签</li>
<li>SWA</li>
<li>……</li>
</ul>
<h2 id="5-分析负例"><a href="#5-分析负例" class="headerlink" title="5. 分析负例"></a>5. 分析负例</h2><p>该过程同样重要，我们需要了解模型在测试数据上的表现情况，在什么数据表现较差，如何优化这些负例。</p>
<p><strong>在优化过程中，建议记录每一次优化信息，分析模型的提升/降低是否符合自己预期，充分利用每一次实验</strong></p>
<p>下面总结了我在优化过程常用的分析方式：</p>
<h3 id="1-检查数据质量是否过差"><a href="#1-检查数据质量是否过差" class="headerlink" title="1. 检查数据质量是否过差"></a>1. 检查数据质量是否过差</h3><p>这种情况通常表现为数据质量较差，模型在原始数据上表现不佳，精确率与召回率都很低。针对这种情况，需要对数据做必要的预处理，让模型能够更好地学习。</p>
<h3 id="2-根据指标进行分析"><a href="#2-根据指标进行分析" class="headerlink" title="2. 根据指标进行分析"></a>2. 根据指标进行分析</h3><h4 id="recall低"><a href="#recall低" class="headerlink" title="recall低"></a>recall低</h4><p>召回率表示召回的数量，测试集数据未召回较多，则从下列角度检查数据：</p>
<ol>
<li>训练集测试集数据差异是否较大，即训练集中是否存在类似数据，若不存在则引入更多数据或者对该数据进行数据增强。<strong>这种情况，常见原因为数据分布不均衡-少数数据训练不充分；训练集、测试集分布差异较大导致</strong></li>
<li>训练集中存在类似数据，检查训练集中该种情况有无标注错误：漏标、错标。</li>
</ol>
<h4 id="precision低"><a href="#precision低" class="headerlink" title="precision低"></a>precision低</h4><p>精确率表示预测出的准确率，测试集数据分错的较多：</p>
<ol>
<li>检查数据分布，是否数据分布不均衡。<strong>数据不均衡导致模型倾向于预测数量较多的数据，精确率下降</strong></li>
<li>标签定义是否准确，是否存在两类标签混淆的情况。<strong>这种情况，需要考虑对标签进行融合</strong></li>
</ol>
<p>类别不均衡常用解决方式：</p>
<ul>
<li>数据增强</li>
<li>resample</li>
<li>reweight</li>
<li>集成学习</li>
</ul>
<p>数据错误常用解决方式：</p>
<ul>
<li>交叉验证</li>
<li>置信学习</li>
<li>聚类分析</li>
</ul>
<p>接下来的过程则是迭代分析，直到模型性能符合业务需求。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://mp.weixin.qq.com/s/RqkQzeR5BOVpU7tj_zUgqQ">https://mp.weixin.qq.com/s/RqkQzeR5BOVpU7tj_zUgqQ</a></p>
<p><a href="https://www.zhihu.com/question/480187938/answer/2103245373">https://www.zhihu.com/question/480187938/answer/2103245373</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/399295895">https://zhuanlan.zhihu.com/p/399295895</a></p>
]]></content>
      <categories>
        <category>年度总结</category>
        <category>2021</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>年度总结</tag>
        <tag>NLP</tag>
        <tag>预训练</tag>
        <tag>对比学习</tag>
        <tag>Prompt</tag>
      </tags>
  </entry>
</search>
